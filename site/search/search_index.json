{"config":{"lang":["en"],"separator":"[\\s\\-\\.]","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Dana Point Capital","text":""},{"location":"--/example/","title":"Example","text":"<pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre> \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] <p>The homomorphism \\(f\\) is injective if and only if its kernel is only the  singleton set \\(e_G\\), because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such  that \\(f(a)=f(b)\\).</p> <pre><code>theme:\nfeatures:\n- content.code.annotate # (1)\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol> <p>The <code>range()</code> function is used to generate a sequence of numbers.</p> Tab 1Tab 2 <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation!</li> </ol> <p>Phasellus posuere in sem ut cursus (1)</p> <ol> <li> I'm an annotation as well!</li> </ol>"},{"location":"advanced_signals/","title":"Transformed Dataset","text":""},{"location":"advanced_signals/nowcast/","title":"Nowcast","text":""},{"location":"api_reference/","title":"API Reference","text":"<p>Strategy is the main implementation of the library for portfolio construction, which initializes the execution of the sequence of blocks and allows to compute tilts/exposures, create and backtest target portfolios.</p> <p></p> <p>Signals constructs transfomed dataset, which are used to build strategies. Examples including High Frequency Indicators, Nowcasts/Forecasts or Alpha Signals.</p>"},{"location":"api_reference/signals/","title":"Signals","text":""},{"location":"api_reference/signals/#docs-work-in-progress","title":"DOCS WORK IN PROGRESS","text":""},{"location":"api_reference/strategy/","title":"Strategy","text":""},{"location":"api_reference/strategy/#strategy_1","title":"Strategy","text":"<p>The main implementation of the library is the <code>Strategy</code> class, which initializes the execution of the sequence and allows to compute tilts/exposures, create and backtest portfolios.</p> <pre><code>opendesk.Strategy(\nsteps: List[Tuple[str, Type, Dict, Dict]], \ntopdown: Optional[bool] = False, \nmapping_table: Optional[Dict[str, str]] = None, \nmapping_weights: Optional[Dict[int, Tuple]] = None\n)\n</code></pre>"},{"location":"api_reference/strategy/#parameters","title":"Parameters","text":"steps<pre><code>List[Tuple[str, Type, Dict, Dict]]\n</code></pre> <p>Alpha blocks in order of execution. More information, please visit the Model Glossary. The parameter <code>steps</code> is required to enable the smooth integration of the strategy into the module with minimal disruption. It is a list of tuples containing:</p> <ul> <li>Custom name of the selected block (e.i. <code>myblock</code>)</li> <li>Class object of the selected block (e.i. <code>MyBlock</code>)</li> <li>Necessary parameters used at the block initialization (<code>__init__</code>) section (e.i. <code>dict(param_1 = \"param_1, param_2 = \"param_2\")</code>)</li> <li>Additional data, <code>**kwargs</code>, required to train the model from the method <code>processing()</code></li> </ul> <p>Example</p> <pre><code>from opendesk.alpha_blocks import Reversion\nsteps=[(\"Reversion\", Reversion)]\n</code></pre> topdown<pre><code>Optional[bool]\n</code></pre> <p>Activates top-down strategy. The strategy tilts is processed at a higher level (e.i. sector level) than the actual allocation exectution (e.i. stock level). If set to <code>True</code>, a mapping table should be passed. Defaults to <code>False</code>.</p> mapping_table<pre><code>Optional[Dict[str, str]]\n</code></pre> <p>Maps higher with lower level assets. Variable <code>topdown</code> needs to be turned to <code>True</code>. Defaults to <code>None</code>.</p> mapping_weights<pre><code>Optional[Dict[int, Tuple]]\n</code></pre> <p>Maps scores with range of weights. Defaults to <code>None</code>.</p>"},{"location":"api_reference/strategy/#instance-variables","title":"Instance Variables","text":""},{"location":"api_reference/strategy/#breakdown","title":"<code>breakdown</code>","text":"breakdown<pre><code>pandas.core.frame.DataFrame\n</code></pre> <p>Output (scores) of all provided blocks. Following the method <code>fit()</code>, the attribute <code>breakdown</code> can be accessed, which contains the output from various models in a single <code>pandas.DataFrame</code> object</p> <pre><code>$ strategy.breakdown\n&lt;span style=\"color: grey;\"&gt;           Model 1  Model 2  Model 3  Model 4\nsector 1        -1        0        2        1\nsector 2         2       -2        0        1\nsector 3         1        1       -2        2\nsector 4        -2        0       -1        0\nsector 5         0       -1       -1        2\nsector 6        -1        0        1       -2\nsector 7        -2        1       -2       -1\nsector 8         1        2        0       -1\nsector 9         0        0       -1        0\nsector 10        2        0        1        0\n&lt;/span&gt;\n</code></pre>"},{"location":"api_reference/strategy/#exposures","title":"<code>exposures</code>","text":"exposures<pre><code>pandas.core.frame.DataFrame\n</code></pre> <p>Strategy exposures/tilts aggregated from model scores.</p>"},{"location":"api_reference/strategy/#group_constraints","title":"<code>group_constraints</code>","text":"group_constraints<pre><code>Optional[Dict[str, Tuple(float, float)]]\n</code></pre> <p>Strategy constraints by group. Product of <code>exposures</code> and <code>mapping_weights</code>.</p>"},{"location":"api_reference/strategy/#lower_bound","title":"<code>lower_bound</code>","text":"lower_bound<pre><code>Dict[str, Tuple]\n</code></pre> <p>Lower bound constraints by group, from <code>group_constraints</code>.</p>"},{"location":"api_reference/strategy/#mid_bound","title":"<code>mid_bound</code>","text":"mid_bound<pre><code>Dict[str, Tuple]\n</code></pre> <p>Mid level constraints by group, from <code>group_constraints</code>.</p>"},{"location":"api_reference/strategy/#upper_bound","title":"<code>upper_bound</code>","text":"upper_bound<pre><code>Dict[str, Tuple]\n</code></pre> <p>Upper level constraints by group, from <code>group_constraints</code>.</p> Group ConstraintsLower BoundMid BoundUpper Bound <p> <pre><code>$ strategy.group_constraints\n&lt;span style=\"color: grey;\"&gt;{'sector 1': (0.0, 0.0),\n'sector 2': (0.05, 0.15),\n'sector 3': (0.0, 0.0),\n'sector 4': (-0.15, -0.05),\n'sector 5': (0.0, 0.0),\n'sector 6': (0.0, 0.0),\n'sector 7': (0.0, 0.0),\n'sector 8': (0.05, 0.15),\n'sector 9': (0.0, 0.0),\n'sector 10': (0.0, 0.0)}\n&lt;/span&gt;\n</code></pre> </p> <p> <pre><code>$ strategy.lower_bound\n&lt;span style=\"color: grey;\"&gt;{'sector 1': 0.0,\n'sector 2': 0.05,\n'sector 3': 0.0,\n'sector 4': -0.15,\n'sector 5': 0.0,\n'sector 6': 0.0,\n'sector 7': 0.0,\n'sector 8': 0.05,\n'sector 9': 0.0,\n'sector 10': 0.0}\n&lt;/span&gt;\n</code></pre> </p> <p> <pre><code>$ strategy.mid_bound\n&lt;span style=\"color: grey;\"&gt;{'sector 1': 0.0,\n'sector 2': 0.1,\n'sector 3': 0.0,\n'sector 4': -0.1,\n'sector 5': 0.0,\n'sector 6': 0.0,\n'sector 7': 0.0,\n'sector 8': 0.1,\n'sector 9': 0.0,\n'sector 10': 0.0}\n&lt;/span&gt;\n</code></pre> </p> <p> <pre><code>$ strategy.upper_bound\n&lt;span style=\"color: grey;\"&gt;{'feature 1': 0.0,\n'feature 2': 0.15,\n'feature 3': 0.0,\n'feature 4': -0.05,\n'feature 5': 0.0,\n'feature 6': 0.0,\n'feature 7': 0.0,\n'feature 8': 0.15,\n'feature 9': 0.0,\n'feature 10': 0.0}\n&lt;/span&gt;\n</code></pre> </p>"},{"location":"api_reference/strategy/#weights","title":"<code>weights</code>","text":"weights<pre><code>Dict[str, float]\n</code></pre> <p>Portfolio weights calculated through the discrete allocation <code>method</code>.</p>"},{"location":"api_reference/strategy/#public-methods","title":"Public Methods","text":"<ul> <li><code>add_blocks()</code> After initialization, additional blocks can be added to <code>steps</code></li> <li><code>check_group_constraints()</code> Check group constraints after creating a portfolio</li> <li><code>discrete_allocation()</code> Set portfolio weights following a discrete allocation procedure</li> <li><code>estimate()</code> Aggregate exposures by summing each units using a predetermined function</li> <li><code>fit()</code> Executes each provided blocks with provided dataset</li> <li><code>optimize()</code> Portfolio optimization, which aims to select the optimal mix of assets in a portfolio in order to satisfy the defined objectives and constraints</li> </ul>"},{"location":"api_reference/strategy/backtest/","title":"Backtest","text":""},{"location":"api_reference/strategy/backtest/#strategybacktest","title":"Strategy.backtest","text":"<pre><code>@classmethod\nopendesk.Strategy.backtest(\npipeline: Pipeline, \n**kwargs\n) \u2011&gt; vectorbt.portfolio.base.Portfolio\n</code></pre> <p>The <code>backtest</code> instance of the <code>Strategy</code> class is a classmethod. It is used to run a simulation using a custom order function <code>from_order_func</code>. It requires <code>BacktestConfig</code> dataclass, a configuration pipeline which simplifies model configurations.</p> <p><code>@classmethod</code></p> <p>A class method is a method that is bound to the class and not the instance of the class. It can be called on the class itself, as well as on any instance of the class. In Python, a class method is defined using the <code>@classmethod</code> decorator.</p> <p>The <code>backtest</code> classmethod initially initializes and fits the strategy using the <code>fit()</code> method, and estimates its exposures using the <code>estimate()</code> method. Afterwards, it constructs a portfolio based on specified orchestration and methodologies at each point in time. The final result is a vectorbt object, which provides access to the full range of functionality offered by the vectorbt ecosystem.</p>"},{"location":"api_reference/strategy/backtest/#parameters","title":"Parameters","text":"config<pre><code>opendesk.backtest.config.BacktestConfig\n</code></pre> <p>Backtesting configuration pipeline <code>dataclass</code>, which includes the necessary parameters to activate the internal strategy builder, is required for this process.</p> kwargs<pre><code>Dict\n</code></pre> <p>Additional parameters for <code>vbt.portfolio.base.Portfolio.from_order_func</code> function.</p>"},{"location":"api_reference/strategy/backtest/#returns","title":"Returns","text":"<p><code>vectorbt.Portfolio.from_order_func</code>: vectorbt <code>Portfolio</code> ecosystem.</p>"},{"location":"api_reference/strategy/backtest/#example-backtest","title":"Example Backtest","text":"<p>The <code>backtest</code> classmethod is initalized through the <code>BacktestPipeline</code> dataclass, which facilitates feature integration. Mandatory variables <code>universe</code>, <code>model_data</code> and <code>steps</code> are set, as follow:</p> <pre><code>$ from opendesk import BacktestConfig\n$ from opendesk import Strategy\n$ config = BacktestConfig(\n$     universe=stock_prices, $     model_data=model_data, $     steps=steps\n$ )\n$ backtest = Strategy.backtest(config)\n$ backtest.stats()\n&lt;span style=\"color: grey;\"&gt;Start                                 2019-01-02 00:00:00\nEnd                                   2022-12-30 00:00:00\nPeriod                                 1008 days 00:00:00\nStart Value                                         100.0\nEnd Value                                      152.092993\nTotal Return [%]                                52.092993\nBenchmark Return [%]                            62.173178\nMax Gross Exposure [%]                          31.819902\nTotal Fees Paid                                       0.0\nMax Drawdown [%]                                13.822639\nMax Drawdown Duration                   320 days 00:00:00\nTotal Trades                                          391\nTotal Closed Trades                                   372\nTotal Open Trades                                      19\nOpen Trade PnL                                  14.614093\nWin Rate [%]                                    54.301075\nBest Trade [%]                                 122.866679\nWorst Trade [%]                               -164.309231\nAvg Winning Trade [%]                           22.115064\nAvg Losing Trade [%]                            -19.44764\nAvg Winning Trade Duration    158 days 21:51:40.990099010\nAvg Losing Trade Duration     143 days 02:49:24.705882354\nProfit Factor                                    1.417933\nExpectancy                                        0.10075\nSharpe Ratio                                     0.942305\nCalmar Ratio                                     0.799575\nOmega Ratio                                      1.179846\nSortino Ratio                                    1.431216\nName: group, dtype: object\n&lt;/span&gt;\n</code></pre>"},{"location":"api_reference/strategy/backtest/#backtestconfig","title":"BacktestConfig","text":"<pre><code>@dataclass\nopendesk.backtest.config.BacktestConfig\n</code></pre> <p><code>@dataclass</code></p> <p>A <code>dataclass</code> is a decorator that is used to define a class that will be used to store data. It automatically generates special methods, such as <code>__init__</code>, <code>__repr__</code>, and <code>__eq__</code>, based on the class's attributes. A dataclass is defined using the <code>@dataclass</code> decorator.</p>"},{"location":"api_reference/strategy/backtest/#parameters_1","title":"Parameters","text":"steps<pre><code>List[Tuple[str, Type, Dict, Dict]]\n</code></pre> <p>Alpha blocks in order of execution. More information, please visit the Model Glossary. The parameter <code>steps</code> is required to enable the smooth integration of the strategy into the module with minimal disruption. It is a list of tuples containing:</p> <ul> <li>Custom name of the selected block (e.i. <code>myblock</code>)</li> <li>Class object of the selected block (e.i. <code>MyBlock</code>)</li> <li>Necessary parameters used at the block initialization (<code>__init__</code>) section (e.i. <code>dict(param_1=\"param_1, param_2=\"param_2\")</code>)</li> <li>Additional data, <code>**kwargs</code>, required to train the model from the method <code>processing()</code></li> </ul> universe<pre><code>pandas.core.frame.DataFrame\n</code></pre> <p>Market price time-series universe, each row is a date and each column is a ticker/id.</p> model_data<pre><code>Optional[pandas.core.frame.DataFrame] = None\n</code></pre> <p>Market returns time-series used to train the model.</p> topdown<pre><code>Optional[bool] = False\n</code></pre> <p>Activates top-down strategy. The strategy tilts is processed at a higher level (e.i. sector level) than the actual allocation exectution (e.i. stock level). If set to <code>True</code>, a mapping table should be passed. Defaults to <code>False</code>.</p> mapping_table<pre><code>Optional[Dict[str, str]] = None\n</code></pre> <p>Maps higher with lower level assets. Variable <code>topdown</code> needs to be turned to <code>True</code>. Defaults to <code>None</code>.</p> mapping_weights<pre><code>Optional[Dict[int, Tuple]] = None\n</code></pre> <p>Maps scores with range of weights. Defaults to <code>None</code>.</p> fit_backend<pre><code>Optional[str] = \"joblib\"\n</code></pre> <p>Run parallel multiprocessing or iterative process.</p> verbose<pre><code>Optional[bool] = None\n</code></pre> <p>Progress messages are printed. Applied to <code>fit()</code> and <code>optimize()</code> functions.</p> estimate<pre><code>Optional[Type] = sum\n</code></pre> <p>Strategy exposures/tilts aggregated from model scores. The <code>func</code> parameter can be any object that is compatible with the <code>.apply</code> function in the pandas library.</p> portfolio_construction<pre><code>Optional[str] = \"optimize\"\n</code></pre> <p>Portfolio construction procedure to allocate weights. It could be <code>optimize</code> or <code>discrete allocation</code>. Defauts to <code>optimize</code></p> optimize_returns_data<pre><code>Optional[bool] = False\n</code></pre> <p>If true, the first argument is returns instead of prices. Defaults to <code>True</code></p> optimize_backend<pre><code>Optional[str] = \"pypfopt\"\n</code></pre> <p>Backend optimizer library. Defaults to <code>pyportopt</code>.</p> <ul> <li><code>pyportopt</code>: PyPortfolioOpt is a library that implements portfolio optimization methods, including classical efficient frontier techniques and Black-Litterman allocation, as well as more recent developments in the field like shrinkage and Hierarchical Risk Parity, along with some novel experimental features, like exponentially-weighted covariance matrices. </li> <li><code>riskfolio</code>: Riskfolio-Lib is a library for making portfolio optimization and quantitative strategic asset allocation in Python. Its objective is to help students, academics and practitioners to build investment portfolios based on mathematically complex models with low effort. It is built on top of CVXPY and closely integrated with pandas data structures.</li> </ul> portfolio_model<pre><code>Optional[str] = \"mvo\"\n</code></pre> <p>Type of optimizer to be used. Type of optimization:</p> <ul> <li><code>mvo</code>: Mean-variance optimization</li> </ul> <p>Work in progress:</p> <ul> <li><code>bl</code>: Black-Litterman allocation</li> <li><code>hrp</code>: Hierarchical Risk Parity</li> <li><code>cla</code>: Critical Line Algorithm</li> </ul> portfolio_expected_returns_params<pre><code>Optional[Dict[str, Any]]\n</code></pre> <p>Parameters to compute an estimate of future returns:</p> <ul> <li><code>method</code> (str): the return model to use. Should be one of:<ul> <li><code>mean_historical_return</code></li> <li><code>ema_historical_return</code></li> <li><code>capm_return</code></li> </ul> </li> <li><code>**kwargs</code>: Method specificities Defaults to:</li> </ul> <pre><code>dict(\nmethod=\"ema_historical_return\", \ncompounding=True, \nspan=500, \nfrequency=252, \nlog_returns=False\n)\n</code></pre> portfolio_cov_matrix_params<pre><code>Optional[Dict[str, Any]]\n</code></pre> <p>Parameters to compute a covariance matrix:</p> <ul> <li><code>method</code> (str): the risk model to use. Should be one of:<ul> <li><code>sample_cov</code></li> <li><code>semicovariance</code></li> <li><code>exp_cov</code></li> <li><code>ledoit_wolf</code></li> <li><code>ledoit_wolf_constant_variance</code></li> <li><code>ledoit_wolf_single_factor</code></li> <li><code>ledoit_wolf_constant_correlation</code></li> <li><code>oracle_approximating</code></li> </ul> </li> <li><code>**kwargs</code>: Method specificities Defautls to:</li> </ul> <pre><code>dict(\nmethod=\"ledoit_wolf\", \nfrequency=252, \nlog_returns=False\n)\n</code></pre> portfolio_weight_bounds<pre><code>Optional[Tuple[int, int]] = (-1, 1)\n</code></pre> <p>Minimum and maximum weight of each asset or single min/max pair if all identical, defaults to (-1, 1). If <code>weight_bounds=(-1, 1)</code>, allows short positions. Defaults to <code>(-1, 1)</code>.</p> porfolio_solver<pre><code>Optional[str] = None\n</code></pre> <p>name of solver. list available solvers with: <code>cvxpy.installed_solvers()</code>.</p> porfolio_solver_options<pre><code>Optional[Dict] = None\n</code></pre> <p>Parameters for the given solver.</p> add_objectives<pre><code>Optional[List[Type]] = None\n</code></pre> <p>List of lambda functions to add new term into the based objective function. This term must be convex, and built from cvxpy atomic functions.</p> add_constraints<pre><code>Optional[List[Type]] = None\n</code></pre> <p>List of lambda function (e.i. all assets &lt;= 3% of the total portfolio = [lambda w: w &lt;= .03]. This constraint must satisfy DCP rules, i.e be either a linear equality constraint or convex inequality constraint.</p> <p>solver_params: Optional[Dict[str, Any]] = field(     default_factory=lambda: dict(         target_volatility=0.08, market_neutral=True     ) )</p> solver_method<pre><code>Optional[str] = \"efficient_risk\"\n</code></pre> <p>Optimization method that can be called (corresponding to different objective functions).</p> <p>Object Instantiation</p> <p>A new EfficientFrontier object should be instantiated if you want to make any change to objectives/constraints/bounds/parameters.  The backtesting framework re-instantiate the optimization process at every rebalancing periods.</p> solver_params<pre><code>Optional[Dict[str, Any]] = dict(target_volatility=0.08, market_neutral=True)\n</code></pre> <p>Optimization method parameters. Defaults to:</p> <pre><code>dict(\ntarget_volatility=0.08, \nmarket_neutral=True\n)\n</code></pre> discrete_allocation_method<pre><code>Optional[str] = \"uniform\"\n</code></pre> <p>Method used to allocate weights.</p> discrete_allocation_range_bound<pre><code>Optional[str] = \"mid\"\n</code></pre> <p>Bound from <code>mapping_weights</code>. Total budget (in %) to apply.</p> backtest_every_nth<pre><code>Optional[int] = 30\n</code></pre> <p>Backtest rebalancing period in days. Defaults to 30. </p> backtest_history_len<pre><code>Optional[int] = -1\n</code></pre> <p>Backtest model training period. If -1, the model trains the entire history. Defaults to -1.</p> backtest_direction<pre><code>Optional[str] = \"long_short\"\n</code></pre> <p>Backtest Direction. It can be <code>long_only</code>, <code>short_only' or</code>long_short<code>. Defaults to</code>long_short`.</p> backtest_backup<pre><code> Optional[str] = \"discrete_allocation\"\n</code></pre> <p>Backtest \"back-up\" used as a fallback in the event that the optimizer is unable to deliver feasible weights. It can be another portfolio construction procedure to allocate weights: <code>optimize</code> or <code>discrete allocation</code>. Defauts to <code>discrete_allocation</code>.</p> backtest_backup_params<pre><code>Optional[Dict[str, Any]] = dict(range_bound=\"mid\")\n</code></pre> <p>Backtest \"back-up\" configuration. Defauts to <code>dict(range_bound=\"mid\")</code> as <code>discrete_allocation</code> is set in <code>backtest_backup</code>.</p>"},{"location":"api_reference/strategy/backtest/#example-backtest_1","title":"Example Backtest","text":"<p>For this example, we are using <code>yfinance</code>, a python library to fetch yahoo market data. First, we import the module and query some tickers from 2019 to 2022: <pre><code>import yfinance as yf\n# Date range\nstart = \"2019-01-01\"\nend = \"2022-12-31\"\n# Tickers of assets\nassets = [\n\"JCI\", \"TGT\", \"CMCSA\", \"CPB\", \n\"MO\", \"APA\", \"MMC\", \"JPM\",\n\"ZION\", \"PSA\", \"BAX\", \"BMY\", \n\"LUV\", \"PCAR\", \"TXT\", \"TMO\",\n\"DE\", \"MSFT\", \"HPQ\", \"SEE\",\n]\n# Downloading data\ndata = yf.download(assets, start=start, end=end)\nstock_prices = data.loc[:, (\"Close\", slice(None))]\nstock_prices.columns = assets\n</code></pre></p> <pre><code>from opendesk.backtest import BacktestConfig\nfrom opendesk.alpha_blocks import Reversion, SignalBased, TrendFollowing\nfrom opendesk.strategy import Strategy\n# Config\nconfig = BacktestConfig(\nuniverse=close_prices,\nsteps=[\n(\"Reversion\", Reversion),\n(\"TrendFollowing\", TrendFollowing),\n],\nportfolio_construction=\"optimize\",\nportfolio_expected_returns_params=dict(\nmethod=\"capm_return\"\n),\nportfolio_cov_matrix_params=dict(\nmethod=\"sample_cov\"\n),\nsolver_method=\"efficient_risk\",\nsolver_params=dict(\ntarget_volatility=0.2, \nmarket_neutral=True\n),\nadd_constraints=[\nlambda w: w &lt;= 0.1, \nlambda w: w &gt;= -0.1\n],\nbacktest_every_nth=30,\n)\n</code></pre> <pre><code>$ backtest = Strategy.backtest(config)\n$ backtest.total_profit(group_by=False)\n&lt;span style=\"color: grey;\"&gt;APA      20.123646\nBAX       6.338269\nBMY      -4.664290\nCMCSA     1.361760\nCPB       1.361636\nDE        8.268657\nHPQ       2.813247\nJCI      11.984073\nJPM       1.150170\nLUV      12.407130\nMMC      -4.770791\nMO       -4.857592\nMSFT      6.389380\nPCAR      5.609880\nPSA       4.577316\nSEE      -2.475789\nTGT      -7.691861\nTMO      -5.878451\nTXT       7.768601\nZION     -7.347374\nName: total_profit, dtype: float64\n&lt;/span&gt;\n</code></pre> <p>More information about the vectorbt ecosystem can be found in the official documentation.</p>"},{"location":"api_reference/strategy/exposures/","title":"Exposures","text":""},{"location":"api_reference/strategy/exposures/#strategyadd_blocks","title":"Strategy.add_blocks","text":"<pre><code>add_blocks(\nself, \n*args: Tuple[str, Type, Dict, Dict]\n) -&gt; opendesk.strategy.Strategy:\n</code></pre> <p>After initialization, additional strategies (blocks) can be added to the instance <code>steps</code>. We included in the below snippet two additionnal examples: A reversion factor and a Markov regime switching model.</p>"},{"location":"api_reference/strategy/exposures/#parameters","title":"Parameters","text":"*args<pre><code>Tuple[str, Type, Dict, Dict]\n</code></pre> <p>Additional blocks to be added.</p>"},{"location":"api_reference/strategy/exposures/#returns","title":"Returns","text":"<p><code>opendesk.strategy.Strategy</code> instance.</p>"},{"location":"api_reference/strategy/exposures/#example-add-blocks","title":"Example Add Blocks","text":"<pre><code>from opendesk import Strategy\nfrom opendesk.alpha_blocks import Reversion, MarkovRegression)\n# pre-trained model\nstrategy = Strategy(steps)\n# print(strategy)\n# Blocks -&gt; signal + gaussian_mixture\nstrategy.add_blocks(\n(\n\"reversion\",\nReversion, # (1)\n{'short_term_rule': None, 'long_term_rule': None}\n),\n(\n\"markov_regression\",\nMarkovRegression, # (2)\n{\"n_phase\": 3},\n{\"cli\": cli}\n)\n)\n</code></pre> <ol> <li>Calculate sentiment using Reversion Ranking Method.     More information provided in the Model Glossary.</li> <li>Calculate sentiment using Trend Following Ranking Method.     More information provided in the Model Glossary.</li> </ol> <pre><code>$ print(strategy)\n&lt;span style=\"color: grey;\"&gt;Blocks -&gt; signal + gaussian_mixture + reversion + markov_regression&lt;/span&gt;\n</code></pre>"},{"location":"api_reference/strategy/exposures/#strategycheck_goup_constraints","title":"Strategy.check_goup_constraints","text":"<pre><code>check_group_constraints(\nself, \nweights: pandas.core.series.Series\n) \u2011&gt; pandas.core.frame.DataFrame\n</code></pre> <p>The performance of the model can be assessed by examining the satisfaction of predetermined constraints. By comparing the output of the model to the set of exposures produced by the actual allocation, it is possible to determine if it is operating as intended. To do this, we use the <code>check_group_constraints()</code> method, which groups assets and sum their weights.</p>"},{"location":"api_reference/strategy/exposures/#parameters_1","title":"Parameters","text":"weights<pre><code>pandas.core.series.Series\n</code></pre> <p>Portfolio weights calculated either with the <code>optimize</code> or the <code>discrete_allocation</code> methods.</p>"},{"location":"api_reference/strategy/exposures/#returns_1","title":"Returns","text":"<p><code>pandas.core.frame.DataFrame</code> object with calculated aggregated weights and target weights.</p>"},{"location":"api_reference/strategy/exposures/#example-group-constraints","title":"Example Group Constraints","text":"<pre><code>from opendesk import Strategy\nfrom opendesk.alpha_blocks import Reversion, TrendFollowing\nstrategy = (\nStrategy(\nsteps=steps,\ntopdown=True,\nmapping_table=mapping_table,\n)\n.fit(df)\n.estimate(sum)\n.optimize(data=stock_prices, backend=\"pypfopt\")\n.portfolio(\nmodel=\"mvo\",\nexpected_returns_params={\n\"method\": \"capm_return\",\n},\ncov_matrix_params={\n\"method\": \"sample_cov\",\n},   \nweight_bounds=(-1, 1)\n)\n.add(\nconstraints=[\nlambda w: w &lt;= 0.1, \nlambda w: w &gt;= -0.1\n]\n)\n)\nstrategy.efficient_risk(target_volatility=0.08, market_neutral=True)\nweights = pd.Series(strategy.clean_weights(), name=\"weights\")\n</code></pre> <pre><code>$ strategy.check_group_constraints(weights)\n&lt;span style=\"color: grey;\"&gt;            weights  target weights\nsector 1      0.15    (0.05, 0.15)\nsector 10     0.10    (0.05, 0.15)\nsector 2      0.00      (0.0, 0.0)\nsector 3      0.00      (0.0, 0.0)\nsector 4     -0.05  (-0.15, -0.05)\nsector 5     -0.15  (-0.15, -0.05)\nsector 6      0.00      (0.0, 0.0)\nsector 7      0.00      (0.0, 0.0)\nsector 8     -0.05  (-0.15, -0.05)\nsector 9      0.00      (0.0, 0.0)\n&lt;/span&gt;\n</code></pre>"},{"location":"api_reference/strategy/exposures/#strategyestimate","title":"Strategy.estimate","text":"<pre><code>estimate(\nself, \nfunc: Type, \ninplace: Optional[bool] = False\n) \u2011&gt; Union[pandas.core.series.Series, opendesk.strategy.Strategy]\n</code></pre> <p>Aggregate exposures by summing each units using a predetermined function <code>func</code>.</p>"},{"location":"api_reference/strategy/exposures/#parameters_2","title":"Parameters","text":"func<pre><code>Type\n</code></pre> <p>Strategy exposures/tilts aggregated from model scores. The <code>func</code> parameter can be any object that is compatible with the <code>.apply</code> function in the pandas library.</p> inplace<pre><code>Optional[bool]\n</code></pre> <p>Returns a copy of <code>exposures</code>.</p>"},{"location":"api_reference/strategy/exposures/#returns_2","title":"Returns","text":"<p><code>opendesk.strategy.Strategy</code> instance.</p>"},{"location":"api_reference/strategy/exposures/#example-estimate","title":"Example Estimate","text":"<p>Some examples of different <code>func</code> parameter are provided below:</p> MeanMedianMaxMin <p> <pre><code>$ strategy.estimate(mean, inplace=True)\n&lt;span style=\"color: grey;\"&gt;sector 1     0.50\nsector 2     0.25\nsector 3     0.50\nsector 4    -0.75\nsector 5     0.00\nsector 6    -0.50\nsector 7    -1.00\nsector 8     0.50\nsector 9    -0.25\nsector 10    0.75\nName: mean, dtype: float64\n&lt;/span&gt;\n</code></pre> </p> <p> <pre><code>$ from statistics import median\n$ strategy.estimate(median, inplace=True)\n&lt;span style=\"color: grey;\"&gt;sector 1     0.5\nsector 2     0.5\nsector 3     1.0\nsector 4    -0.5\nsector 5    -0.5\nsector 6    -0.5\nsector 7    -1.5\nsector 8     0.5\nsector 9     0.0\nsector 10    0.5\nName: median, dtype: float64\n&lt;/span&gt;\n</code></pre> </p> <p> <pre><code>$ from statistics import median\n$ strategy.estimate(median, inplace=True)\n&lt;span style=\"color: grey;\"&gt;sector 1     2\nsector 2     2\nsector 3     2\nsector 4     0\nsector 5     2\nsector 6     1\nsector 7     1\nsector 8     2\nsector 9     0\nsector 10    2\nName: max, dtype: int64\n&lt;/span&gt;\n</code></pre> </p> <p> <pre><code>$ from statistics import median\n$ strategy.estimate(median, inplace=True)\n&lt;span style=\"color: grey;\"&gt;sector 1    -1\nsector 2    -2\nsector 3    -2\nsector 4    -2\nsector 5    -1\nsector 6    -2\nsector 7    -2\nsector 8    -1\nsector 9    -1\nsector 10    0\nName: min, dtype: int64\n&lt;/span&gt;\n</code></pre> </p>"},{"location":"api_reference/strategy/exposures/#strategyfit","title":"Strategy.fit","text":"<pre><code>fit(\nself, \nmodel_data: pandas.core.frame.DataFrame, \nbackend: Optional[str] = 'joblib', \nverbose: Optional[bool] = True\n) \u2011&gt; opendesk.strategy.Strategy\n</code></pre> <p>Executes each provided blocks with common dataset.</p>"},{"location":"api_reference/strategy/exposures/#parameters_3","title":"Parameters","text":"model_data<pre><code>pandas.core.frame.DataFrame\n</code></pre> <p>Market returns time-series used to train the model.</p> backend<pre><code>Optional[str] = \"joblib\"\n</code></pre> <p>Run parallel multiprocessing or iterative process.</p> verbose<pre><code>Optional[bool] = None\n</code></pre> <p>Joblib progress messages are printed.</p>"},{"location":"api_reference/strategy/exposures/#returns_3","title":"Returns","text":"<p><code>opendesk.strategy.Strategy</code> instance.</p>"},{"location":"api_reference/strategy/exposures/#example-fit","title":"Example Fit","text":"<p>After initializing the class, the market returns can be fit using the <code>fit()</code> method, as in the following example:</p> <pre><code>strategy = Strategy(steps).fit(df)\n</code></pre> <p>This returns the instance object <code>self</code> on which the method was called. </p> <p>Fluent interface</p> <p>In object-oriented programming, returning self from a method allows for the implementation of a fluent interface, where methods can be cascaded i a single statement.</p> <p>In object-oriented programming, returning <code>self</code> from a method can be useful for several reasons. One common use case is to create a fluent interface, which is an API design style that allows method calls to be chained together in a single statement. This can make the code more readable and concise, as it eliminates the need to create intermediate variables to store the results of intermediate method calls. For example, with a fluent interface, this code could be written as <code>results = SomeClass().method1().method2().method3()</code>. </p>"},{"location":"api_reference/strategy/portfolio_construction/","title":"Porfolio Construction","text":"<p>Portfolio construction, which involves translating scores into weights, can be a complex and nuanced process. We have developed two methods that allows for greater flexibility and experimentation: Optimization and Discrete Allocation. These approach enables the exploration of a wide range of potential portfolio compositions.</p> <p></p> <p>Optimization capabilities, which is the process of selecting the optimal mix of assets in a portfolio, with respect to the alpha scores, in order to maximize returns while minimizing risk, facilitate the portfolio construction process.</p> <p></p> <p>Discrete Allocation allows the implementation of single or multiple pre-determined rule-based allocation strategies. It builds optimal, high level, diversified portfolios, at scale. </p>"},{"location":"api_reference/strategy/portfolio_construction/discrete_allocation/","title":"Discrete Allocation","text":""},{"location":"api_reference/strategy/portfolio_construction/discrete_allocation/#strategydiscrete_allocation","title":"Strategy.discrete_allocation","text":"<pre><code>discrete_allocation(\nself, \nmethod: Optional[str] = 'uniform', \nrange_bound: Optional[str] = 'mid'\n) \u2011&gt; opendesk.strategy.Strategy\n</code></pre> <p>Discrete allocation allows the implementation of single or multiple pre-determined rule-based allocation strategies. It builds optimal, high level, diversified portfolios, at scale. </p>"},{"location":"api_reference/strategy/portfolio_construction/discrete_allocation/#parameters","title":"Parameters","text":"method<pre><code>Optional[str]\n</code></pre> <p>Method used to allocate weights.</p> range_bound<pre><code>Optional[str]\n</code></pre> <p>Bound from <code>mapping_weights</code>. Total budget (in %) to apply.</p>"},{"location":"api_reference/strategy/portfolio_construction/discrete_allocation/#returns","title":"Returns","text":"<p><code>opendesk.strategy.Strategy</code> instance</p>"},{"location":"api_reference/strategy/portfolio_construction/discrete_allocation/#example-discrete-allocation","title":"Example Discrete Allocation","text":"<pre><code>from opendesk import Strategy\nfrom opendesk.alpha_blocks import Reversion, TrendFollowing\nstrategy = Strategy(steps=steps, topdown=True, mapping_table=mapping_table)\nstrategy.fit(df).estimate(sum)\nstrategy.discrete_allocation(\nmethod=\"uniform\", \nrange_bound=\"mid\"\n)\n</code></pre> <pre><code>$ weights = pd.Series(strategy.weights, name=\"weights\")\n&lt;span style=\"color: grey;\"&gt;asset 1      0.00\nasset 2      0.01\nasset 3      0.00\nasset 4      0.00\nasset 5      0.01\nasset 96     0.00\nasset 97    -0.01\nasset 98     0.00\nasset 99    -0.01\nasset 100    0.00\nName: weights, Length: 100, dtype: float64\n&lt;/span&gt;\n</code></pre>"},{"location":"api_reference/strategy/portfolio_construction/optimize/","title":"Optimization","text":""},{"location":"api_reference/strategy/portfolio_construction/optimize/#strategyoptimize","title":"strategy.optimize","text":"<pre><code>Strategy.optimize(\nself, \ndata: Optional[pandas.core.frame.DataFrame] = None, \nreturns_data: Optional[bool] = False, \nbackend: Optional[str] = 'pypfopt'\n) \u2011&gt; opendesk.strategy.Strategy\n</code></pre> <p>Portfolio optimization capabilities, which is the process of selecting the optimal mix of assets in a portfolio, with respect to the alpha scores, in order to maximize returns while minimizing risk. The <code>Strategy.optimizer()</code> method has been implemented to streamline the process of optimization and facilitate the integration of backtesting.</p> <p>The <code>Strategy.optimize</code> (backend) calls the <code>Optimizer</code> class, which includes the implementation of the following public methods:</p> <ul> <li><code>add()</code> Add a new objectives and constraints to the optimization problem</li> <li><code>portfolio()</code> Base optimizer model</li> </ul>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#parameters","title":"Parameters","text":"data<pre><code>Optional[pandas.core.frame.DataFrame]\n</code></pre> <p>Market price time-series, each row is a date and each column is a ticker/id.</p> returns_data<pre><code>Optional[bool] = True\n</code></pre> <p>If true, the first argument is returns instead of prices. Defaults to <code>True</code></p> backend<pre><code>Optional[str] = \"pypfopt\"\n</code></pre> <p>Backend optimizer library. Defaults to <code>pyportopt</code>.</p> <ul> <li><code>pyportopt</code>: PyPortfolioOpt is a library that implements portfolio optimization methods, including classical efficient frontier techniques and Black-Litterman allocation, as well as more recent developments in the field like shrinkage and Hierarchical Risk Parity, along with some novel experimental features, like exponentially-weighted covariance matrices. </li> <li><code>riskfolio</code>: Riskfolio-Lib is a library for making portfolio optimization and quantitative strategic asset allocation in Python. Its objective is to help students, academics and practitioners to build investment portfolios based on mathematically complex models with low effort. It is built on top of CVXPY and closely integrated with pandas data structures.</li> </ul>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#returns","title":"Returns","text":"<p><code>opendesk.strategy.Strategy</code> instance.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#optimizer","title":"Optimizer","text":"<pre><code>class optimizer.Optimizer(\nself,\ndata: pandas.core.frame.DataFrame,\ngroup_constraints: Optional[Dict[str, Tuple[float, float]]],\ntopdown: Optional[bool] = False,\nmapping_table: Optional[Dict[str, str]] = None,\nreturns_data: Optional[bool] = False,\n)\n</code></pre> <p>Initalize portfolio optimization processes.</p> <p>New Object Instantiation</p> <p>A new object should be instantiated if you want to make any change to objectives/constraints/bounds/parameters.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#parameters_1","title":"Parameters","text":"data<pre><code>pandas.core.frame.DataFrame\n</code></pre> <p>Adjusted closing prices of the asset, each row is a date and each column is a ticker/id. If returns data, variable <code>returns_data</code> should be turned to <code>True</code>.</p> group_constraints<pre><code>Optional[Dict[str, Tuple(float, float)]]\n</code></pre> <p>Strategy constraints by group. Product of <code>exposures</code> and <code>mapping_weights</code>.</p> mapping_table<pre><code>Optional[Dict[str, str]]\n</code></pre> <p>Maps higher with lower level assets. Variable <code>topdown</code> needs to be turned to <code>True</code>. Defaults to <code>None</code>.</p> returns_data<pre><code>Optional[bool]\n</code></pre> <p>If true, the first argument is returns instead of prices. Defaults to False.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#public-methods","title":"Public Methods","text":""},{"location":"api_reference/strategy/portfolio_construction/optimize/#optimizeradd","title":"Optimizer.add","text":"<p>Add a new objectives and constraints to the optimization problem.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#parameters_2","title":"Parameters","text":"objectives<pre><code>Optional[List[Type]] = None\n</code></pre> <p>List of lambda functions to add new term into the based objective function. This term must be convex, and built from cvxpy atomic functions.</p> constraints<pre><code>Optional[List[Type]] = None\n</code></pre> <p>List of lambda function (e.i. all assets &lt;= 3% of the total portfolio = [lambda w: w &lt;= .03]. This constraint must satisfy DCP rules, i.e be either a linear equality constraint or convex inequality constraint.</p> <p>Top-Down Method</p> <p>When <code>topdown</code> is set to <code>True</code>, it adds constraints on the sum of weights of different groups of assets. Most commonly, these will be sector constraints e.g portfolio\u2019s exposure to tech must be less than x%.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#returns_1","title":"Returns","text":"<p><code>opendesk.optimizer.Optimizer</code> instance.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#optimizerportfolio","title":"Optimizer.portfolio","text":"<p>Base optimizer model, allowing for the efficient computation of optimized asset weights. The portfolio method houses different optimization methods, which generate optimal portfolios for various possible objective functions and parameters.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#parameters_3","title":"Parameters","text":"model<pre><code>Optional[str] = \"mvo\"\n</code></pre> <p>Type of optimizer to be used. Type of optimization:</p> <ul> <li><code>mvo</code>: Mean-variance optimization</li> </ul> <p>Work in progress:</p> <ul> <li><code>bl</code>: Black-Litterman allocation</li> <li><code>hrp</code>: Hierarchical Risk Parity</li> <li><code>cla</code>: Critical Line Algorithm</li> </ul> expected_returns_params<pre><code>Dict[str, Any]\n</code></pre> <p>Parameters to compute an estimate of future returns:</p> <ul> <li><code>method</code> (str): the return model to use. Should be one of:<ul> <li><code>mean_historical_return</code></li> <li><code>ema_historical_return</code></li> <li><code>capm_return</code></li> </ul> </li> <li><code>**kwargs</code>: Method specificities</li> </ul> cov_matrix_params<pre><code>Dict[str, Any]\n</code></pre> <p>Parameters to compute a covariance matrix:</p> <ul> <li><code>method</code> (str): the risk model to use. Should be one of:<ul> <li><code>sample_cov</code></li> <li><code>semicovariance</code></li> <li><code>exp_cov</code></li> <li><code>ledoit_wolf</code></li> <li><code>ledoit_wolf_constant_variance</code></li> <li><code>ledoit_wolf_single_factor</code></li> <li><code>ledoit_wolf_constant_correlation</code></li> <li><code>oracle_approximating</code></li> </ul> </li> <li><code>**kwargs</code>: Method specificities</li> </ul> weight_bounds<pre><code>Optional[Tuple[int, int]] = (-1, 1)\n</code></pre> <p>Minimum and maximum weight of each asset or single min/max pair if all identical, defaults to (-1, 1). If <code>weight_bounds=(-1, 1)</code>, allows short positions.</p> kwargs<pre><code>Dict\n</code></pre> <p>Model specificities.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#returns_2","title":"Returns","text":"<p><code>opendesk.optimizer.Optimizer</code> instance.</p>"},{"location":"api_reference/strategy/portfolio_construction/optimize/#example-optimize","title":"Example Optimize","text":"<p>Portfolio construction, which involves optimizing the allocation of assets within a portfolio, can be a complex and nuanced process. We have developed a method that allows for greater flexibility and experimentation in the portfolio optimization process. This approach enables the exploration of a wide range of potential portfolio compositions, and the example provided illustrates this method applied from the initial stages of portfolio construction:</p> <ul> <li>A mapping table, <code>mapping_table</code>, has been defined to specify the group membership of each investable stocks</li> <li>The base model is set <code>mvo</code>, the Mean-Variance Optimization from the pypfopt library, with the appropriate return and risk models</li> <li>The weight bounds parameter, <code>weight_bounds</code> is set to <code>(-1, 1)</code>, which serves as the first constraint by limiting the minimum and maximum weight of each asset in portfolios that allow short positions</li> <li>Additionally, new constraints are introduced to the optimization problem in the form of convex inequalities, which ensure that long positions do not exceed 10% and short positions do not fall below -10%</li> </ul> <pre><code>from opendesk import Strategy\nfrom opendesk.alpha_blocks import Reversion\nsteps = [(\"reversion\", Reversion)] # (1)\nstrategy = (\nStrategy(\nsteps,\ntopdown=True,\nmapping_table=mapping_table # (4)\n)\n.fit(df) # (2)\n.estimate(sum)\n.optimize(\ndata=stock_prices, # (3)\nbackend=\"pypfopt\"        \n)\n.portfolio(\nmodel=\"mvo\",\nexpected_returns_params={\n\"method\": \"capm_return\",\n},\ncov_matrix_params={\n\"method\": \"sample_cov\",\n},   \nweight_bounds=(-1, 1) # (5)\n)\n.add(\nobjectives=None,\nconstraints=[\nlambda w: w &lt;=  .1, \nlambda w: w &gt;= -.1\n] # (6)\n)\n)\n</code></pre> <ol> <li>Calculate sentiment using Reversion Ranking Method.     More information provided in the Model Glossary.</li> <li>pandas.DataFrame object, with specifiy the variation of sector returns over time.</li> <li>pandas.DataFrame object, with specifiy the variation of stock prices over time.</li> <li>Mapping table where stock ticker/id are keys and sector name are values.</li> <li><code>weight_bounds</code> parameter serves as a constraint by limiting the minimum and maximum weight of each asset in portfolios. Because it ranges from <code>-1</code> to <code>1</code>, it allows Long and Shorts.</li> <li>Users can add new constraints in a form of lambda function as the user need to the optimization problem. This constraint must satisfy DCP rules, i.e be either a linear equality constraint or convex inequality constraint.</li> </ol> <p>The wrapper class creates <code>portfolio</code>, a public method, allowing for the efficient computation of optimized asset weights through inheritance. Here is an example with <code>efficient_risk()</code>, which maximises return for a given target risk of 8% (<code>target_volatility=.08</code>) and market neutrality (<code>market_neutral=True</code>):</p> <pre><code>$ strategy.efficient_risk(target_volatility=.08, market_neutral=True)\n$ weights = pd.Series(strategy.clean_weights(), name=\"weights\")\n&lt;span style=\"color: grey;\"&gt;asset 1      0.10\nasset 2      0.03\nasset 3     -0.02\nasset 4      0.03\nasset 5     -0.05\nasset 96     0.00\nasset 97    -0.09\nasset 98     0.00\nasset 99    -0.07\nasset 100    0.00\nName: weights, Length: 100, dtype: float64\n&lt;/span&gt;\n</code></pre>"},{"location":"contributing/","title":"Developement Guildeline","text":""},{"location":"contributing/development_guidelines/","title":"Development Guidelines","text":""},{"location":"contributing/development_guidelines/#abstract-classes-abcs","title":"Abstract Classes (ABCs)","text":"<p>An abstract class can be considered as a blueprint for other classes. It allows you to create a set of methods that must be created within any child classes built from the abstract class. </p> <ul> <li>A class which contains one or more abstract methods is called an abstract class. </li> <li>An abstract method is a method that has a declaration but does not have an implementation. </li> <li>While we are designing large functional units we use an abstract class.</li> <li>When we want to provide a common interface for different implementations of a component, we use an abstract class.\u00a0</li> </ul>"},{"location":"contributing/development_guidelines/#why-are-abcs-useful","title":"Why are ABCs useful?","text":"<p>By defining an abstract base class, you can define a common Application Program Interface(API) for a set of subclasses. This capability is especially useful in situations where a third-party is going to provide implementations, such as with plugins, but can also help you when working in a large team or with a large code-base where keeping all classes in your mind is difficult or not possible.</p>"},{"location":"contributing/development_guidelines/#how-abcs-work","title":"How ABCs work?","text":"<p>ABC</p> <p>Find more information about abc \u2014 Abstract Base Classes.</p> <p>By default, Python does not provide abstract classes. Python comes with a module that provides the base for defining Abstract Base classes (ABC) and that module name is <code>ABC</code>. <code>ABC</code> works by decorating methods of the base class as abstract and then registering concrete classes as implementations of the abstract base. A method becomes abstract when decorated with the keyword <code>@abstractmethod</code>. </p>"},{"location":"contributing/development_guidelines/#base-score-model","title":"Base Score Model","text":"<p>In order to ensure consistency and ease of use, all blocks must adhere to the <code>BaseScoreModel</code> abstract base class. </p> <pre><code>from typing import Dict\nimport pandas as pd\nfrom abc import ABC, abstractmethod\nclass BaseScoreModel(ABC):\n@abstractmethod\ndef processing(\nself, X: pd.DataFrame, **kwargs) -&gt; \"BaseScoreModel\":\nself.processing_output: pd.DataFrame\nreturn self\n@abstractmethod\ndef ranking(self) -&gt; \"BaseScoreModel\":\nself.ranking_output: pd.DataFrame\nreturn self\n@abstractmethod\ndef scoring(self) -&gt; \"BaseScoreModel\":\nself.scoring_output: pd.DataFrame\nself.strategy_output: Dict\nreturn self\n</code></pre> <p>This set of rules allows us to seamlessly integrate blocks and reduces friction. As a result, the code becomes more readable, easier to debug, and simpler to contribute to. It also significantly decreases the amount of code required to access information.</p>"},{"location":"contributing/development_guidelines/#step-1-inheritance","title":"Step 1: Inheritance","text":"<p>Blocks must inherite from <code>BaseScoreModel</code>:</p> <pre><code>from opendesk import BaseScoreModel\nclass MyBlock(BaseScoreModel)\n...\n</code></pre>"},{"location":"contributing/development_guidelines/#step-2-initialize-parameters","title":"Step 2: Initialize Parameters","text":"<p>Parameters should be initialized at the <code>__init__</code> section of the class. It also means that model data should NOT be passed at this stage (see step 5 below):</p> <pre><code>from opendesk import BaseScoreModel\nclass MyBlock(BaseScoreModel)\ndef __init__(self, param_1, param_2, param_n):\nself.param_1 = param_1\nself.param_2 = param_2\nself.param_n = param_n\n</code></pre>"},{"location":"contributing/development_guidelines/#step-3-prs","title":"Step 3: PRS","text":"<p>Blocks must follow the \"PRS\" schema, which is \"Processing\" data, \"Ranking\" results, \"Scoring\" output. All classes must have the mandatory three functions:</p> <ul> <li><code>processing()</code></li> <li><code>ranking()</code></li> <li><code>scoring()</code></li> </ul> <pre><code>from opendesk import BaseScoreModel\nclass MyBlock(BaseScoreModel)\ndef __init__(self, param_1, param_2, param_n):\nself.param_1 = param_1\nself.param_2 = param_2\nself.param_n = param_n\ndef processing(self)\n...\ndef ranking(self)\n...\ndef scoring(self)\n...\n</code></pre>"},{"location":"contributing/development_guidelines/#step-4-fluent-interface","title":"Step 4: Fluent Interface","text":"<p>Each of the above three functions must return the instance object <code>self</code> on which the method was called:</p> <pre><code>from opendesk import BaseScoreModel\nclass MyBlock(BaseScoreModel)\ndef __init__(self, param_1, param_2, param_n):\nself.param_1 = param_1\nself.param_2 = param_2\nself.param_n = param_n\ndef processing(self) -&gt; \"MyBlock\":\nreturn self\ndef ranking(self) -&gt; \"MyBlock\":\nreturn self\ndef scoring(self) -&gt; \"MyBlock\":\nreturn self\n</code></pre> <p>Fluent interface</p> <p>In object-oriented programming, returning self from a method allows for the implementation of a fluent interface, where methods can be cascaded i a single statement.</p> <p>In object-oriented programming, returning <code>self</code> from a method can be useful for several reasons. One common use case is to create a fluent interface, which is an API design style that allows method calls to be chained together in a single statement. This can make the code more readable and concise, as it eliminates the need to create intermediate variables to store the results of intermediate method calls. For example, with a fluent interface, this code could be written as <code>results = SomeClass().method1().method2().method3()</code>. </p>"},{"location":"contributing/development_guidelines/#step-5-processing-parameters","title":"Step 5: Processing Parameters","text":"<p>The function <code>processing()</code> must accept a market price <code>pandas.DataFrame</code> time-series object and can accept additional dataset (within <code>**kwargs</code>):</p> <pre><code>import pandas as pd\nfrom opendesk import BaseScoreModel\nclass MyBlock(BaseScoreModel)\ndef __init__(self, param_1, param_2, param_n):\nself.param_1 = param_1\nself.param_2 = param_2\nself.param_n = param_n\ndef processing(self, X: pd.DataFrame, **kwargs) -&gt; \"MyBlock\":\nreturn self\ndef ranking(self) -&gt; \"MyBlock\":\nreturn self\ndef scoring(self) -&gt; \"MyBlock\":\nreturn self\n</code></pre>"},{"location":"contributing/development_guidelines/#step-6-set-attributes","title":"Step 6: Set Attributes","text":"<p>Functions <code>processing()</code>, <code>ranking()</code> and <code>scoring()</code> must set attributes <code>processing_output</code>, <code>ranking_output</code> and <code>scoring_output</code> as <code>pandas.DataFrame</code> object, respectively:</p> <pre><code>import pandas as pd\nfrom opendesk import BaseScoreModel\nclass MyBlock(BaseScoreModel)\ndef __init__(self, param_1, param_2, param_n):\nself.param_1 = param_1\nself.param_2 = param_2\nself.param_n = param_n\ndef processing(self, X: pd.DataFrame, **kwargs) -&gt; \"MyBlock\":\nself.processing_output: pd.DataFrame\nreturn self\ndef ranking(self) -&gt; \"MyBlock\":\nself.ranking_output: pd.DataFrame\nreturn self\ndef scoring(self) -&gt; \"MyBlock\":\nself.scoring_output: pd.DataFrame\nreturn self\n</code></pre>"},{"location":"contributing/development_guidelines/#step-7-strategy-output","title":"Step 7: Strategy Output","text":"<p>The function <code>scoring()</code> must set attribute <code>strategy_output</code> as dictionnary object, representing the final scores of the model:</p> <pre><code>from typing import Dict\nimport pandas as pd\nfrom opendesk import BaseScoreModel\nclass MyBlock(BaseScoreModel)\ndef __init__(self, param_1, param_2, param_n):\nself.param_1 = param_1\nself.param_2 = param_2\nself.param_n = param_n\ndef processing(self, X: pd.DataFrame, **kwargs) -&gt; \"MyBlock\":\nself.processing_output: pd.DataFrame\nreturn self\ndef ranking(self) -&gt; \"MyBlock\":\nself.ranking_output: pd.DataFrame\nreturn self\ndef scoring(self) -&gt; \"MyBlock\":\nself.scoring_output: pd.DataFrame\nself.strategy_output: Dict\nreturn self\n</code></pre>"},{"location":"contributing/philosophy/","title":"Philosophy","text":"<p>The engineering and research process in the context of investment strategies involves several key stages.</p> <ol> <li>Research phase: In this phase, the focus is on gathering and analyzing data to inform the development of a quantitative model or algorithm. This involves collecting data from various sources, such as financial statements, market trends, and economic indicators, and using statistical and mathematical techniques to analyze and interpret the data.</li> <li>Strategy implementation: Once the research phase is complete, the next step is to implement the quantitative model or algorithm. </li> <li>Model Optimization: After the initial implementation of the quantitative model, it is important to continuously review and optimize it to ensure that it is accurately predicting outcomes and providing valuable insights. This may involve  adjusting the model's parameters or adding additional data sources to improve its performance.</li> <li>Backtesting: Before implementing a quantitative model in a live trading environment, it is often useful to backtest it to see how it would have performed in the past. This can help to identify any potential weaknesses or areas for improvement in the model.</li> <li>Target and invested portfolio: In the context of quantitative analysis, the target portfolio refers to the desired mix of investments that the model is intended to identify and select, while the invested portfolio refers to the actual mix of investments that has been chosen based on the model's predictions.</li> <li>Risk monitoring: It is important to continuously monitor the portfolio for any potential risks and to take appropriate action to mitigate those risks. This involves regularly reviewing the portfolio and making adjustments as needed, as well as staying informed about market trends and economic conditions.</li> </ol> <pre><code>sequenceDiagram\n  Database-&gt;&gt;Blocks: Feed Strategy\n  Blocks-&gt;&gt;Portfolio: Compute Exposures\n  Portfolio-&gt;&gt;Backtest: Weights\n  loop Objectives &amp; Constraints\n        Backtest-&gt;&gt;Portfolio: Performance\n    end</code></pre> <p>Overall, the engineering and research process in the context of quantitative analysis involves a systematic approach to collecting and analyzing data, developing and implementing a quantitative model or algorithm, and continuously reviewing and optimizing it to ensure that it is providing accurate and valuable insights.</p>"},{"location":"data_workflow/","title":"Index","text":""},{"location":"data_workflow/#data-workflow","title":"Data workflow","text":"<p>What is AWS CloudFormation?</p> <p>Documentation available on What is AWS CloudFormation? - AWS CloudFormation</p> <pre><code>sequenceDiagram\n    Data Provider-&gt;&gt;AWS S3: File Upload\n    AWS S3--&gt;&gt;AWS Lambda: Trigger Lambda Function\n    AWS Lambda--&gt;&gt;AWS DynamoDB: Metadata Store\n    AWS Lambda--&gt;&gt;AWS S3: Extract File Uploaded\n    AWS S3--&gt;&gt;AWS Lambda: Trigger Lambda Function\n    AWS Lambda--&gt;&gt;AWS S3: HTML Upload\n    AWS S3-&gt;&gt;Terminal: Online Access</code></pre> <p>AWS CloudFormation is a service that helps you model and set up your AWS  resources so that you can spend less time managing those resources and more  time focusing on your applications that run in AWS. You create a template that  describes all the AWS resources that you want (like Amazon EC2 instances or  Amazon RDS DB instances), and CloudFormation takes care of provisioning and  configuring those resources for you. You don't need to individually create and configure AWS resources and figure out what's dependent on what; CloudFormation  handles that. The following scenarios demonstrate how CloudFormation can help.</p>"},{"location":"dataset/","title":"Transformed Dataset","text":""},{"location":"dataset/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"getting_started/","title":"Opendesk","text":"<p>This Get Started guide explains how Opendesk works, how to install Opendesk on your preferred operating system, and how to create your first Opendesk strategy!</p> <p></p> <p>Installation helps you set up your virtual environment and walks you through installing Opendesk on Windows, macOS, and Linux. Regardless of which package management tool and OS you're using, we recommend running the commands on this page in a virtual environment.</p> <p></p> <p>Main concepts introduces you to Opendesk's base model and development flow. You'll learn what makes Opendesk the most powerful way to build systematic strategies, including the ability to customize existing setup. </p> <p></p> <p>Create Blocks following the three-step process outlined in Opendesk's core guidelines: process raw data, rank and compare these results, create and map a sequence of scores.</p> <p></p> <p>Optimize Blocks, which is the process of selecting the optimal mix of assets in a portfolio, with respect to the alpha scores, in order to maximize returns while minimizing risk. This method has been implemented to streamline the process of optimization and facilitate the integration of backtesting.</p> <p></p> <p>Backtest Blocks using Opendesk's vectorbt wrapper to test one or multiple strategies at once, optimizes portfolio and provides access to the full range of functionality offered by the vectorbt ecosystem.</p>"},{"location":"getting_started/backtest_blocks/","title":"Backtest Blocks","text":""},{"location":"getting_started/backtest_blocks/#open-source-resources","title":"Open-Source Resources","text":"<p>This platform aggregates a range of state-of-the-art tools and libraries and facilitates their automation through a unified interface. This allows users to easily access and utilize a wide range of advanced resources for their research or development efforts, streamlining the process of utilizing cutting-edge technologies.</p> <p>There is a wide range of options available for Python when it comes to selecting a backtesting framework. A comprehensive list of these libraries can be found on the GitHub page titled awesome-quant. We initially experimented with one called Backtesting and then subsequently tested a few others.</p> Backtesting bt vectorbt backtrader How easy is strategy creation? <code>EASY</code> <code>HARD</code> <code>EASY</code> <code>EASY</code> How quick is it? <code>FAST</code> <code>UNKNOWN</code> <code>FAST</code> <code>FAST</code> How easy is extracting metrics? <code>MEDIUM</code> <code>UNKNOWN</code> <code>MEDIUM</code> <code>HARD</code> <p>vectorbt</p> <p>For the purpose of backtesting, vectorbt can be considered as a suitable initial choice for integrating our model pipeline due to its fast performance and ease of use. It also actively managed and a more advance version has been created: vectorbt pro.</p>"},{"location":"getting_started/backtest_blocks/#vectorbt","title":"Vectorbt","text":""},{"location":"getting_started/backtest_blocks/#abstract","title":"Abstract","text":"<p>Vectorbt is a powerful tool that combines the functionality of a fast backtester with advanced data analysis capabilities. It enables users to analyze and evaluate a wide range of trading options, instruments, and time periods with ease, enabling them to identify patterns and optimize their strategy. It allows users to explore and understand complex phenomena in trading data, providing them with valuable insights that can inform their decision-making and potentially give them an informational advantage in the market.</p> <p>Vectorbt utilizes a vectorized representation of trading strategies in order to optimize performance. This representation involves storing multiple strategy instances in a single multi-dimensional array, as opposed to the traditional object-oriented programming (OOP) approach of representing strategies as classes and data structures. The vectorized representation used by vectorbt allows for more efficient processing and comparison of strategies, and can particularly improve the speed of analysis when dealing with quadratic programming problems.</p> <p>vectorbt is a Python package for quantitative analysis that takes a novel approach to backtesting: it operates entirely on pandas and NumPy objects, and is accelerated by Numba to analyze any data at speed and scale. This allows for testing of many thousands of strategies in seconds.</p> <p>The three main <code>Portfolio</code> methods are:</p> <ul> <li><code>from_orders()</code></li> <li><code>from_signals()</code></li> <li><code>from_order_func()</code></li> </ul> <p>These methods go through each row and column in the input data provided by the user, and at each step they turn the current element into an order request. They then process this request by updating the current simulation state and adding the filled order record to an array. This array and other information can be used later on to analyze the simulation during the reconstruction phase.</p>"},{"location":"getting_started/backtest_blocks/#numba","title":"Numba","text":"<p>Numba is a just-in-time (JIT) compiler for Python that is designed to improve the performance of Python code. It does this by compiling Python code to native machine instructions, which can be executed much faster than the interpreted code that is normally used in Python. Numba works by decorating functions or methods with a special <code>@jit</code> decorator, which tells the Numba compiler to compile the function for faster execution. Numba can be used to speed up code that makes heavy use of Python's scientific and numerical libraries, such as NumPy and SciPy, as well as code that performs CPU-bound operations. In addition to its JIT compiler, Numba also provides support for parallel programming through its <code>@vectorize</code> and <code>@guvectorize</code> decorators, which can be used to parallelize the execution of certain types of functions.</p> <p>Numba and Third Party Packages</p> <p>Numba is a tool that can significantly improve the speed of code execution. However, it does not support integration with third-party development. Therefore, our current portfolio optimization implementation, which uses PyPortfolioOpt and RiskFolio-Lib, does not utilize Numba, but still maintains efficient performance.</p>"},{"location":"getting_started/backtest_blocks/#step-by-step-example","title":"Step-by-Step Example","text":"<p>The <code>backtest</code> classmethod within the <code>Strategy</code> class utilizes the vectorbt library to test and evaluate the performance of a given strategy. Vectorbt is a Python package that provides fast and scalable quantitative analysis using pandas and NumPy objects, and is optimized for speed using Numba. </p> <p>In the field of software engineering, it is recommended that a function be designed in a manner that promotes testability by adhering to the principles of cohesion. Specifically, this entails limiting the function's scope to a single, well-defined task, as well as minimizing the number of arguments it accepts. </p> <p>In cases where a function is required to operate on multiple arguments, it is suggested to employ techniques such as encapsulation by utilizing higher-level objects to group the arguments together. This allows for more robust and maintainable codebase.</p> <p>This is why we created <code>Pipeline</code>, a dataclass object, which encapsultes required arguments to create exposure and build portfolio at each rebalancing period.</p>"},{"location":"getting_started/backtest_blocks/#step-1-backtestpipeline","title":"Step 1: BacktestPipeline","text":"<p>The <code>backtest</code> method is initalized through the <code>BacktestPipeline</code> dataclass, which facilitates feature integration. For example, variables <code>universe</code>, <code>model_data</code>, <code>steps</code>, <code>topdown</code> and <code>mapping_table</code> are set to match your requirement. All other variables are pre-set.</p> <pre><code>from opendesk import Pipeline\npipeline = BacktestPipeline(\nuniverse=stock_prices, \nmodel_data=model_data, \nsteps=[(\n\"my_block\", \nMyBlock, \n{\"mapping_score\": mapping_score}, \n{\"price_earnings\": price_earnings}\n)], \ntopdown=True, \nmapping_table=mapping_table,\nportfolio_construction='optimize',\nportfolio_expected_returns_params=dict(\nmethod=\"capm_return\"\n),\nportfolio_cov_matrix_params=dict(\nmethod=\"sample_cov\"\n),\nsolver_method=\"efficient_risk\",\nsolver_params=dict(\ntarget_volatility=.08, \nmarket_neutral=True\n),\nadd_constraints = [\nlambda w: w &lt;=  .03, \nlambda w: w &gt;= -.03\n],\nbacktest_backup=\"discrete_allocation\"\n)\n</code></pre> <p>The backtest implementation initializes, fits and estimates exposures using the <code>fit()</code> and the <code>estimate()</code> methods. Then, it optimizes the portfolio at the stock level using the <code>optimize().portfolio()</code> methods and finds weights that align with the desired level of risk. </p> <p>The strategy is rebalanced on a monthly basis, and a <code>discrete_allocation</code> is used as a fallback in the event that the optimizer is unable to deliver feasible weights.</p>"},{"location":"getting_started/backtest_blocks/#step-2-backtest","title":"Step 2: Backtest","text":"<p>The output is a vectorbt.Portfolio object, which allows users to leverage the entire vectorbt ecosystem.</p> <pre><code>$ backtest = Strategy.backtest(pipeline)\n$ backtest.stats()\n&lt;span style=\"color: grey;\"&gt;Start                                 2019-01-02 00:00:00\nEnd                                   2022-12-30 00:00:00\nPeriod                                 1008 days 00:00:00\nStart Value                                         100.0\nEnd Value                                      152.092993\nTotal Return [%]                                52.092993\nBenchmark Return [%]                            62.173178\nMax Gross Exposure [%]                          31.819902\nTotal Fees Paid                                       0.0\nMax Drawdown [%]                                13.822639\nMax Drawdown Duration                   320 days 00:00:00\nTotal Trades                                          391\nTotal Closed Trades                                   372\nTotal Open Trades                                      19\nOpen Trade PnL                                  14.614093\nWin Rate [%]                                    54.301075\nBest Trade [%]                                 122.866679\nWorst Trade [%]                               -164.309231\nAvg Winning Trade [%]                           22.115064\nAvg Losing Trade [%]                            -19.44764\nAvg Winning Trade Duration    158 days 21:51:40.990099010\nAvg Losing Trade Duration     143 days 02:49:24.705882354\nProfit Factor                                    1.417933\nExpectancy                                        0.10075\nSharpe Ratio                                     0.942305\nCalmar Ratio                                     0.799575\nOmega Ratio                                      1.179846\nSortino Ratio                                    1.431216\nName: group, dtype: object\n&lt;/span&gt;\n</code></pre>"},{"location":"getting_started/create_blocks/","title":"Create Blocks","text":"<p>Blocks are classes, which follow Opendesk's Development Guidelines, to ensure consistency and ease of use. Blocks must follow the \"PRS\" schema, which is \"Processing\" data, \"Ranking\" results, \"Scoring\" output. All classes must have the below three functions:</p> <ul> <li><code>processing()</code></li> <li><code>ranking()</code></li> <li><code>scoring()</code></li> </ul>"},{"location":"getting_started/create_blocks/#step-by-step-example","title":"Step-by-Step Example","text":"<p>Dependencies</p> <p>For this step-by-step example, we are using the following dependencies: <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n</code></pre></p> <p>In this example, we want to create a valuation level strategy. This rule-based strategy implies exposing our portfolio to directional bets, depending on both the level of the price-earning ratio (PE) time-series and the cross-sectional comparison between assets.</p> <ol> <li>In the processing function, we will standardize features by removing the mean and scaling to unit variance. The standard score, \\(Z\\), of a sample \\(x\\) is calculated as \\(Z = \\frac{(x - \\mu)}{\\sigma}\\), where \\(\\mu\\) is the mean of the training samples and \\(\\sigma\\) is the standard deviation of the training samples.</li> <li>In the ranking function, we will rank in ascending order \\(PEs\\).</li> <li>In the scoring function, we will map top quantiles from both long and short sides. </li> </ol>"},{"location":"getting_started/create_blocks/#step-1-processing","title":"Step 1: Processing","text":"<p>To process data, we use the Scikit-Learn <code>StdandardScaler</code> transform. In practice, normalizing our time-series is as follow:</p> <pre><code>def processing(price_earnings: pd.DataFrame):\nprocessing_output = (\nStandardScaler()\n.set_output(transform=\"pandas\")\n.fit_transform(price_earnings)\n)\nreturn processing_output\n</code></pre> <p>Which returns a <code>pandas.DataFrame</code> object.</p>"},{"location":"getting_started/create_blocks/#step-2-ranking","title":"Step 2: Ranking","text":"<p>Then, the transformed results is ranked using <code>pandas.rank()</code> function:</p> <pre><code>def ranking():\nranking_output = (\nprocessing_output\n.iloc[-1]\n.rename(\"rank\")\n.rank(ascending=False)\n.sort_values()\n)\nreturn ranking_output\n</code></pre> <p>Which also returns a <code>pandas.DataFrame</code> object.</p>"},{"location":"getting_started/create_blocks/#step-3-scoring","title":"Step 3: Scoring","text":"<p>Finally, we produce the goal of this base score model is to produce quantile scores, as follow:</p> <pre><code>def scoring():\nquantiles = pd.qcut(ranking_output, q=5, labels=False)\nscoring_output = quantiles.map(mapping_score)\nreturn strategy_output\n</code></pre>"},{"location":"getting_started/create_blocks/#step-4-parameters","title":"Step 4: Parameters","text":"<p>Last, for reproductibility and ease, we aim to gather parameters in the <code>__init__</code> section:</p> <pre><code>from typing import Dict\nfrom opendesk.blueprints import BaseScoreModel\nclass MyBlock(BaseScoreModel):\ndef __init__(self, mapping_score: Dict)\nself.mapping_score = mapping_score\n</code></pre>"},{"location":"getting_started/create_blocks/#step-5-wrapping-things-up","title":"Step 5: Wrapping Things Up","text":"<pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom opendesk.blueprints import BaseScoreModel\nclass MyBlock(BaseScoreModel):\ndef __init__(self, mapping_score: Dict)\nself.mapping_score = mapping_score\ndef processing(self, price_earnings: pd.DataFrame) -&gt; \"MyBlock\":\nself.processing_output = (\nStandardScaler()\n.set_output(transform=\"pandas\")\n.fit_transform(price_earnings)\n)\nreturn self\ndef ranking(self) -&gt; \"MyBlock\":\nself.ranking_output = (\nprocessing_output\n.iloc[-1]\n.rename(\"rank\")\n.rank(ascending=False)\n.sort_values()\n)\nreturn self\ndef scoring(self) -&gt; \"MyBlock\":\nquantiles = pd.qcut(ranking_output, q=5, labels=False)\nself.scoring_output = quantiles.map(mapping_score)\nself.strategy_output = scoring_output.to_dict()\nreturn self\n</code></pre>"},{"location":"getting_started/installation/","title":"Installation","text":""},{"location":"getting_started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before you get started, you're going to need a few things:</p> <ul> <li>Your favorite IDE or text editor</li> <li>Python 3.10</li> <li>PIP</li> <li>Install C++:</li> <li>MacOS: You need to install XCode Command Line Tools. They are required to compile some of Opendesk's Python dependencies during installation.</li> <li>Windows: For Windows users, download Visual Studio, with additional instructions.</li> </ul> <p>Python</p> <p>Opendesk is built on Python. Other dependencies, such as C++, are employed to improve the speed at which the program runs.</p>"},{"location":"getting_started/installation/#set-up-your-virtual-environment","title":"Set up your virtual environment","text":"<p>Regardless of which package management tool you're using, we recommend running the commands on this page in a virtual environment. This ensures that the dependencies pulled in for Opendesk don't impact any other Python projects you're working on.</p> <p>Below are a few tools you can use for environment management:</p> <ul> <li>pipenv</li> <li>poetry</li> <li>venv</li> <li>virtualenv</li> <li>conda</li> </ul>"},{"location":"getting_started/installation/#install-opendesk","title":"Install Opendesk","text":"<p>Troubleshooting</p> <p>If any of these methods don\u2019t work, please raise an issue with the \u2018packaging\u2019 label on GitHub.</p> <p>prior to using the below commands, you may need to follow the installation instructions for cvxopt and cvxpy).</p>"},{"location":"getting_started/installation/#with-pip","title":"With Pip recommended","text":"<p>Installation can be done via pip:</p> <pre><code>$ pip install opendesk\n---&gt; 100%\n</code></pre>"},{"location":"getting_started/installation/#with-poetry","title":"With Poetry recommended","text":"<p>Poetry is a relatively new kid on the block but has gained traction due to its ease of use and how it resolves several issues over Conda.</p> <p>Poetry will set up your virtual environment and install all required packages with one command <code>poetry install</code>. In addition, it can build installable packages with <code>poetry build</code>, which can be installed by pip. It uses the PEP Standard pyproject.toml file to define dependencies and build options for other tools (e.g. pytest arguments).</p> <p>It respects <code>.python_version</code> files, uses a lock file to define specific versions of packages and pip to install them - thus, you have reproducible environments installed quickly.</p> <p>The only downside is the slight learning curve in changing your workflow.</p> <pre><code>$ poetry add opendesk\n---&gt; 100%\n</code></pre>"},{"location":"getting_started/installation/#with-conda","title":"With Conda","text":"<p>If you don't have Anaconda install yet, follow the steps provided on the Anaconda installation page.</p> <pre><code>$ conda install opendesk\n---&gt; 100%\n</code></pre>"},{"location":"getting_started/installation/#with-git","title":"With Git","text":"<p>The alternative is to clone the project:</p> <pre><code>$ git clone https://github.com/ActurialCapital/xyz.git\n$ cd myproject\n$ python setup.py install\n</code></pre>"},{"location":"getting_started/installation/#further-reading","title":"Further Reading","text":"<p>A pretty good guide/supporting argument to the recommended setup - My Python Development Environment, 2020 Edition - Jacob Kaplan-Moss.</p>"},{"location":"getting_started/main_concepts/","title":"Main Concepts","text":"<p>Using OpenDesk is easy. First, come up with an idea and make sure it can be organized in a clear and concise way. Then, build one or more \"blocks\" that bring this idea to life, following OpenDesk's core guidelines. Finally, create a portfolio and test it out through backtesting to see how it performs.</p> <p>Building alpha blocks is a methodology which involves a sequential application of multiple, modular strategies. These blocks are rule-based and can be easily modified, added, or removed from the sequence. Each block returns a score, and the overall approach is designed to facilitate the integration of research and the efficient testing and optimization of strategies and Machine Learning overlaye, while also allowing for the risk-efficient combination of different sources of alpha. The building blocks approach is a comprehensive yet extensible method for data analysis and financial strategy development. </p>"},{"location":"getting_started/main_concepts/#features","title":"Features","text":"<ul> <li> Portfolio strategy first: Opendesk focuses on portfolio strategy development</li> <li> Fast: Opendesk system has been designed to achieve superior performance in the development, implementation, and evaluation of strategies, built with NumPy and Pandas</li> <li> Fast to code: Created through fluent interface, which is an API design style that allows method calls to be chained together in a single statement. This make Opendesk's code more readable and concise, as it eliminates the need to create intermediate variables to store the results of temporary method calls.</li> <li> Intuitive: Develop a plan, organize your ideas, conduct research, implement strategies based on the findings, and test various parameters to determine their impact in a single session.</li> <li> Easy: Opendesk user interface has been optimized for simplicity and ease of use, reducing the need for extensive training or consultation of documentation.</li> <li> <p> Batteries included: </p> <ul> <li>Quantitative data pre-processing</li> <li>ML and scientific computing</li> <li>Large and diversified model library</li> <li>Flexible portfolio construction</li> <li>Fast Backtesting capabilities</li> <li>AWS CloudFormation service integrated</li> <li>FastAPI web framework built-in</li> </ul> </li> </ul> <p>Our platform integrates a diverse set of state-of-the-art tools and libraries, including those for machine learning, data analysis, and scientific computing. These resources are carefully curated to ensure that they represent the most advanced and effective technologies currently available.</p>"},{"location":"getting_started/main_concepts/#alpha-blocks","title":"Alpha blocks","text":"<p>The alpha block sequence is a modular approach to creating investment strategies that involves breaking down the code pipeline into individual units, or \"blocks,\" that can be easily replaced or removed. Each block is designed to function as a rule-based strategy, contributing to the overall views and confidence assigned to a particular asset. This approach, which was first proposed by Kowalski1 (1979), involves arranging blocks of code in a specific sequence in order to generate an output.The modular design of building sequences allows for easy expansion and integration of alpha sources. This approach has already been well-established in computer science and software engineering (Bass, Clements, &amp; Kazman, 20032). It is escpecially powerful for integrating research, as it allows for the combination of alpha sources in a risk-sensitive manner and leads towards efficient backtesting and optimization.</p> <p>Did you know?</p> <p>There are several scientific references that support the use of modular approaches and building blocks in investment strategy development. For example, in their paper \"Modular Investment Strategies,\" published in the Journal of Financial Economics3, K. G. Rouwenhorst and G. S. Wu discuss the benefits of using a modular approach to constructing investment strategies.  They argue that this approach allows for better risk management, as it allows for the independent testing and evaluation of each component of the strategy. Another scientific reference that supports the use of building blocks in investment strategy development is the paper \"Building Investment Strategies with Building Blocks,\" published in the Journal of Portfolio Management4. In this paper, the authors discuss the benefits of using a building block approach, including the ability to easily incorporate new research and the flexibility to adjust the strategy as market conditions change.</p>"},{"location":"getting_started/main_concepts/#scores","title":"Scores","text":"<p>Scores are numerical values that are used to evaluate or rank various options or candidates. In order to generalize the results, a score is generated for each block of data, which serves as a signal to adjust the level of exposure to a particular asset or group of assets:</p> <ul> <li>Scores allow for flexibility: By calculating scores, you can easily adjust the relative importance of different factors and criteria, or even add or remove factors as needed. This flexibility can be useful when an your goals or circumstances change.</li> <li> <p>Scores can be more easily customized: Scores can be customized to reflect your specific goals, risk tolerance, and other factors. This can make it easier for you to create portfolios that are tailored to your individual needs and preferences.</p> </li> <li> <p>Scores can help to incorporate subjective factors: Some investment decisions involve subjective judgment, such as whether a company's management team is strong or whether a particular market is likely to experience significant growth in the near future. Scores can be used to incorporate these subjective factors in a systematic way.</p> </li> <li> <p>Scores can be used to compare investments on a common scale: By assigning scores to different investments, you can more easily compare them to one another on a common scale. This can make it easier to identify the most attractive candidates for inclusion in a portfolio.</p> </li> <li> <p>Scores extend optimization processes: The optimization process can use these scores to select the investment portfolio that maximizes returns while minimizing risk, subject to any constraints or objectives that have been defined.</p> </li> </ul>"},{"location":"getting_started/main_concepts/#model-design","title":"Model Design","text":"<p>The building blocks approach involves sequentially executing multiple steps on a dataset, allowing for the modification of steps, step parameters, and the order in which they are executed. Each block represents a modular, rule-based strategy that can be removed or replaced in the sequence. These blocks return a score for each feature. This approach is designed to facilitate the integration of alpha sources, while also being easily extensible.</p> <pre><code>graph LR\n  id1[(Database)] --&gt; B[Strategy];\n  B --&gt; C[Block A] &amp; D[Block B] &amp; E[Block N];\n  C --&gt; I[/Exposures/];\n  D --&gt; I;\n  E --&gt; I;</code></pre>"},{"location":"getting_started/main_concepts/#multiprocessing","title":"Multiprocessing","text":"<p>Using multiprocessing can be an efficient way to integrate the blocks. Multiprocessing refers to the ability of a computer to execute multiple processes concurrently, which can be useful for completing tasks more quickly. By utilizing multiprocessing to integrate each individual units, it is possible to speed up the process of constructing code pipelines and evaluating the performance of investment strategies or models.</p> <pre><code>graph LR\n  id1[(Database)] --&gt; B[Strategy];\n  B --&gt; C[Block A] &amp; D[Block B] &amp; E[Block N];\n  subgraph Multiprocessing\n  C --- F[/Score A/];\n  D --- G[/Score B/];\n  E --- H[/Score N/];\n  end\n  F --&gt; I[/Exposures/];\n  G --&gt; I;\n  H --&gt;I;</code></pre> AdvantagesLimitations <ol> <li>Improved performance: Multiprocessing can improve the performance of your program by allowing it to utilize multiple CPU cores, which can speed up the execution of CPU-bound and multithreaded programs.</li> <li>Better utilization of resources: Multiprocessing allows you to make use of all available CPU cores, which can be especially useful when running programs on a machine with multiple cores or on a multi-core server.</li> <li>Easier parallelization: Python's Joblib module provides a high-level interface for creating and managing processes, making it easier to write parallelized programs. Joblib provides a  simple helper class to write parallel for loops using multiprocessing. The core idea is to write the code to be executed as a generator expression, and convert it to parallel computing.</li> </ol> <p>However, it is important to note that the efficiency of using multiprocessing will depend on the specific characteristics of the blocks and the hardware being used. It may be necessary to carefully analyze the performance of the code and the available resources in order to determine the most appropriate approach for integrating the blocks in the sequence.</p>"},{"location":"getting_started/main_concepts/#speed","title":"Speed","text":"<p>In the above example, 5 blocks (processes) were executed concurrently using backend <code>LokyBackend</code> with 8 concurrent workers5, each operating on a dataset of 1000 samples times 20 sectors.</p> <p>The elapsed time for this operation was 1.2 seconds.</p> <pre><code>$ strategy.fit(df).estimate(sum)\n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:   &lt;/span&gt;&lt;span style=\"color: lime;\"&gt;Done 1 tasks&lt;/span&gt;\n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:   &lt;/span&gt;&lt;span style=\"color: lime;\"&gt;Done 2 out of 5&lt;/span&gt;    \n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:   &lt;/span&gt;&lt;span style=\"color: lime;\"&gt;Done 3 out of 5&lt;/span&gt;\n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:   &lt;/span&gt;&lt;span style=\"color: lime;\"&gt;Done 4 out of 5&lt;/span&gt; \n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:   &lt;/span&gt;&lt;span style=\"color: lime;\"&gt;Done 5 out of 5 | elapsed: 1.2s finished&lt;/span&gt;\n</code></pre>"},{"location":"getting_started/main_concepts/#step-by-step-example","title":"Step-by-Step Example","text":"<p>Let's design the following strategy:</p> <ul> <li>Long-Short Equity</li> <li>Top-Down (from sector to stock level)</li> <li>Risk optimized (8% target volatility)</li> <li>Market neutral</li> <li>Sentiment-based, which integrates both sector momentum reversion and trend following techniques.</li> </ul>"},{"location":"getting_started/main_concepts/#step-1-blocks","title":"Step 1: Blocks","text":"<p>To calculate scores, we follow a set of predefined rules that compute the deviation between long-term and short-term sector rankings. This generates a composite factor that averages the relative price return momentum within each sector. These techniques can be found in the sentiment folder under the <code>Reversion</code> and <code>TrendFollowing</code> alpha blocks. For more information about these techniques and other blocks, please visit the Model Glossary.</p> <p>The Strategy class is initialized by defining the steps as outlined above and setting the <code>topdown</code> parameter to <code>True</code>. </p> <pre><code>from opendesk import Strategy\nfrom opendesk.alpha_blocks import Reversion, TrendFollowing\nstrategy = Strategy(\nsteps = [\n(\"reversion\", Reversion),\n(\"trend_following\", TrendFollowing)\n],\ntopdown=True, \nmapping_table=mapping_table\n)\n</code></pre> <p>Mapping Table</p> <p>Because we are implementing a top-down strategy (parameter <code>topdown=True</code>), the <code>mapping_table</code> is also passed. The mapping table is a dictionnary, which associates stocks with sectors, as follow:</p> <p> <pre><code>$ pd.Series(mapping_table)\n&lt;span style=\"color: grey;\"&gt;stock 1       sector 1\nstock 2       sector 2\nstock 3       sector 3\nstock 4       sector 4\nstock 5       sector 5\n                ...  \nstock 96      sector 6\nstock 97      sector 7\nstock 98      sector 8\nstock 99      sector 9\nstock 100     sector 10\nLength: 100, dtype: object\n&lt;/span&gt;\n</code></pre> </p>"},{"location":"getting_started/main_concepts/#step-2-exposures","title":"Step 2: Exposures","text":"<p>The returns time-series (at the sector level) are fit using the <code>fit()</code> method, and the portfolio exposures (tilts) are estimated through <code>estimate()</code> by summing the individual scores:</p> <pre><code>$ strategy.fit(model_data).estimate(sum)\n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:&lt;/span&gt;   &lt;span style=\"color: lime;\"&gt;1 tasks&lt;/span&gt;\n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:&lt;/span&gt;   &lt;span style=\"color: lime;\"&gt;Done 2 out of 2 | elapsed: 0.5s&lt;/span&gt;\n&lt;span style=\"color: yellow;\"&gt;[Parallel(n_jobs=-1)]:&lt;/span&gt;   &lt;span style=\"color: lime;\"&gt;Done 2 out of 2 | elapsed: 0.5s finished&lt;/span&gt;\n</code></pre> <p>A summary breakdown and final tilts can be shown using the <code>breakdown</code> and <code>exposure</code> attributes, respectively.:</p> Breakdown Exposures <p> <pre><code>$ strategy.breakdown\n&lt;span style=\"color: grey;\"&gt;           Trendfollowing  Reversion\nsector 1                1          1\nsector 2                0          1\nsector 3                0          0\nsector 4               -2          0\nsector 5               -1         -1\nsector 6                2         -2\nsector 7                2         -1\nsector 8               -2          0\nsector 9               -1          0\nsector 10               1          2\nName: sum, dtype: int64 \n&lt;/span&gt;\n</code></pre> </p> <p> <pre><code>$ strategy.exposures\n&lt;span style=\"color: grey;\"&gt;sector 1     2\nsector 2     1\nsector 3     0\nsector 4    -2\nsector 5    -2\nsector 6     0\nsector 7     1\nsector 8    -2\nsector 9    -1\nsector 10    3\nName: sum, dtype: int64\n&lt;/span&gt;\n</code></pre> </p>"},{"location":"getting_started/main_concepts/#step-3-portfolio-construction","title":"Step 3: Portfolio Construction","text":"<p>Let's find individual stocks weights. To accomplish this, you can use the <code>optimize()</code> method, which allows us to align the portfolio with your objectives and constraints. </p> <p>The modular structure of our code pipeline enables you to choose various optimization techniques, return estimation methods, and risk models within the <code>portfolio()</code> method, leveraging open-source capabilities. </p> <p>Additionally, we have the ability to incorporate additional constraints using the <code>add()</code> method, such as lower and upper bounds for each individual stocks. You can adjust the weightings of you investment strategy in order to achieve a targeted level of volatility and market neutrality, as follow:</p> <pre><code># Optimize portfolio\nportfolio = (\nstrategy\n.optimize(stock_prices) # (1)\n.portfolio(\nmodel=\"mvo\",\nexpected_returns_params=dict(\nmethod: \"capm_return\"\n), # (2)\ncov_matrix_params=dict(\nmethod=\"sample_cov\"\n), # (3)\nweight_bounds=(-1, 1) # (4)\n)\n.add(\nconstraints=[\nlambda w: w &lt;=  0.1, \nlambda w: w &gt;= -0.1\n]\n)\n)\n# Solver target volatility and market neutrality\nportfolio.efficient_risk(target_volatility=0.08, market_neutral=True)\n</code></pre> <ol> <li>Because it is a top-down strategy, we want to optimize your portfolio (finding weights which align with both objectives and constraints) at the stock level.</li> <li>Mean-variance optimization requires knowledge of the expected returns.</li> <li>Mean-variance optimization requires a risk model for quantifying asset risk. Commonly, the covariance matrix, which describes asset volatilities and their co-dependence, is used.</li> <li>Minimum and maximum weight of each asset. When <code>weight_bounds=(-1, 1)</code>, it allows for portfolios with shorting.</li> </ol> <p>To finalize the portfolio weightings, we can utilize <code>clean_weights()</code>, a utility function provided by the PyPortfolioOpt library and integrated within <code>Strategy</code>. This function allows us to filter out any weightings with absolute values below a specified cutoff, setting them to zero, and rounding the remaining entities.</p> <pre><code>$ weights = pd.Series(portfolio.clean_weights(), name=\"weights\")\n&lt;span style=\"color: grey;\"&gt;asset 1     -0.09\nstock 2      0.09\nstock 3     -0.08\nstock 4      0.00\nstock 5      0.00\nstock 96     0.06\nstock 97    -0.04\nstock 98     0.00\nstock 99     0.00\nstock 100    0.00\nName: weights, Length: 100, dtype: float64\n&lt;/span&gt;\n</code></pre> <ol> <li> <p>Kowalski, M. (1979). Algorithm = logic + control. Communications of the ACM, 22(7), 424-436.\u00a0\u21a9</p> </li> <li> <p>Bass, L., Clements, P., &amp; Kazman, R. (2003). Software architecture in practice (2nd ed.). Boston, MA: Addison-Wesley.\u00a0\u21a9</p> </li> <li> <p>Rouwenhorst, K. G., &amp; Wu, G. S. (2001). Modular investment strategies. Journal of Financial Economics, 61(3), 369-403.\u00a0\u21a9</p> </li> <li> <p>Faber, M., &amp; O'Shaughnessy, J. (2013). Building investment strategies with building blocks. Journal of Portfolio Management, 39(4), 104-115.\u00a0\u21a9</p> </li> <li> <p>By default joblib.Parallel uses the 'loky' backend module to start separate Python worker processes to execute tasks concurrently on separate CPUs. More information available in the Joblib Documentation.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting_started/optimize_blocks/","title":"Optimize Blocks","text":"<p>Portfolio optimization is the process of selecting the optimal mix of assets in a portfolio in order to maximize returns while minimizing risk. One method of portfolio optimization involves the use of alpha scores. By selecting assets with high alpha scores, an investor can potentially achieve higher probability of positive returns while taking on the same level of risk. The optimal portfolio is typically determined through the use of statistical analysis and optimization techniques, such as mean-variance or Black-Litterman optimization.</p> <p>Portfolio optimization using alpha scores has been studied extensively in the financial literature. For example, in a study published in the Journal of Financial Economics1, Chen, Novy-Marx, and Zhang (2013) found that portfolios constructed using alpha scores significantly outperformed traditional market-cap weighted portfolios. Another study by Geczy, Musto, and Reed (2005) published in the Review of Financial Studies2 found that portfolios constructed using alpha scores had higher Sharpe ratios (a measure of risk-adjusted returns) compared to traditional portfolios.</p> <p>Black-Litterman Approach</p> <p>This method is also particularly useful in the Black-Litterman  (BL) model, which is a Bayesian approach to asset allocation. The BL model combines an initial estimate of returns with specific views on certain assets to generate a revised estimate of expected returns. This revised estimate, known as the posterior estimate, is then used to optimize the allocation of assets in accordance with a predetermined set of objectives (e.g., maximizing Sharpe ratio) and constraints.</p> <p>Risk Considerations</p> <p>It's important to note that while alpha scores can be useful for portfolio optimization, they are not a guarantee of success. Like any investment strategy, portfolio optimization using alpha scores carries its own set of risks and uncertainties. It is always important for investors to carefully consider their investment goals and risk tolerance before making any investment decisions.</p>"},{"location":"getting_started/optimize_blocks/#key-takeaways","title":"Key Takeaways","text":"<p>An interval query is used to assign scores to elements in a portfolio. These scores are then used to determine the relative weightings of the highest and lowest elements in the portfolio. The resulting portfolio reflects these weightings and adheres to any specified objectives and constraints.</p> <pre><code>sequenceDiagram\n  Exposures-&gt;&gt;Map: Default Config File\n  Exposures--&gt;Map: Custom Config File\n  Map-&gt;&gt;Portfolio: Range Bound Constraints\n  Portfolio--&gt;&gt;Optimizer: Parameters\n  Portfolio--&gt;&gt;Optimizer: Objectives\n  Portfolio--&gt;&gt;Optimizer: Constraints\n  Optimizer-&gt;&gt;Portfolio: Weights</code></pre> <p>Why Are We Not Creating Weights in the First Place?</p> <p>There are a few reasons why you might calculate scores rather than directly assigning \"weights\" to potential assets in their investment portfolios. </p> <p>One reason is that scores can be used to rank potential investments relative to one another, while weights are typically used to indicate the proportion of your total portfolio that should be allocated to a particular asset. This means that scores can be used to identify which assets are the most attractive candidates for inclusion in a portfolio, while weights are used to determine how much of an your capital should be allocated to each asset. </p> <p>Another reason is that scores can be based on a variety of different factors and criteria, whereas weights are usually based on a single factor (e.g., expected return or risk). By using scores, you can take a more holistic view of potential investments and consider multiple factors when making decisions. </p> <p>Furthermore, the allocation of weights in the portfolio would not consider the overall goals and limitations of the portfolio. It would only be based on the weights where alpha scores have been calculated, such as at the sector level.</p>"},{"location":"getting_started/optimize_blocks/#step-by-step-example","title":"Step-by-Step Example","text":"<p>Portfolio construction, which involves optimizing the allocation of assets within a portfolio, can be a complex and nuanced process. We have developed a method that allows for greater flexibility and experimentation in the portfolio optimization process. This approach enables the exploration of a wide range of potential portfolio compositions, and the example provided illustrates this method applied from the initial stages of portfolio construction.</p> <pre><code>from opendesk import Strategy\nfrom opendesk.alpha_blocks import Reversion\nstrategy = Strategy([(\"reversion\", Reversion)]).fit(df).estimate(sum) # (1)\n</code></pre> <ol> <li>Calculate sentiment using Reversion Ranking Method.     More information provided in the Model Glossary.</li> </ol>"},{"location":"getting_started/optimize_blocks/#step-1-optimize","title":"Step 1: Optimize","text":"<p>We aim to find weights for a large universe of stocks:</p> <pre><code>strategy.optimize(data=stock_prices) # (1)\n</code></pre> <ol> <li>pandas.DataFrame object, with specifiy the variation of stock prices over time.</li> </ol>"},{"location":"getting_started/optimize_blocks/#step-2-portfolio","title":"Step 2: Portfolio","text":"<p>The wrapper class creates <code>portfolio</code>, a public method, allowing for the efficient computation of optimized asset weights through inheritance:</p> <pre><code>strategy.portfolio(\nmodel=\"mvo\",\nexpected_returns_params={\"method\": \"capm_return\"},\ncov_matrix_params={\"method\": \"sample_cov\"},   \nweight_bounds=(-1, 1) # (1)\n)\n</code></pre> <ol> <li><code>weight_bounds</code> parameter serves as a constraint by limiting the minimum and maximum weight of each asset in portfolios. Because it ranges from <code>-1</code> to <code>1</code>, it allows Long and Shorts.</li> </ol>"},{"location":"getting_started/optimize_blocks/#step-3-add-objectives-constraints","title":"Step 3: Add Objectives &amp; Constraints","text":"<p>Constraints are lambda functions (e.i. all assets must be lower or equal to 10% of the total portfolio would simply translate to <code>[lambda w: w &lt;= .1]</code>. This constraint must satisfy DCP rules, i.e be either a linear equality constraint or convex inequality constraint. We added the following:</p> <pre><code>strategy.add(constraints=[lambda w: w &lt;= .1, lambda w: w &gt;= -.1]) # (1)\n</code></pre> <ol> <li>Users can add new constraints in a form of lambda function as the user need to the optimization problem. This constraint must satisfy DCP rules, i.e be either a linear equality constraint or convex inequality constraint.</li> </ol>"},{"location":"getting_started/optimize_blocks/#step-4-weights","title":"Step 4: Weights","text":"<p>Here is an example with <code>efficient_risk()</code>, which maximises return for a given target risk of 8% (<code>target_volatility=.08</code>) and market neutrality (<code>market_neutral=True</code>):</p> <pre><code>$ strategy.efficient_risk(target_volatility=.08, market_neutral=True)\n$ weights = pd.Series(strategy.clean_weights(), name=\"weights\")\n&lt;span style=\"color: grey;\"&gt;asset 1      0.10\nasset 2      0.03\nasset 3     -0.02\nasset 4      0.03\nasset 5     -0.05\nasset 96     0.00\nasset 97    -0.09\nasset 98     0.00\nasset 99    -0.07\nasset 100    0.00\nName: weights, Length: 100, dtype: float64\n&lt;/span&gt;\n</code></pre> <ol> <li> <p>Chen, L., Novy-Marx, R., &amp; Zhang, L. (2013). Factor Premia and Interaction with the Market Portfolio. Journal of Financial Economics, 110(1), 1-35.\u00a0\u21a9</p> </li> <li> <p>Geczy, C., Musto, D., &amp; Reed, A. (2005). A simple approach to performance attribution for hedge funds: the case of equity market neutral strategies. Review of Financial Studies, 18(2), 367-384.\u00a0\u21a9</p> </li> </ol>"},{"location":"model_glossary/","title":"Model Glossary","text":""},{"location":"model_glossary/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/phase_identification/","title":"Phase Identification","text":"<p>While academics have focused on type I (false positive) and type II errors  (false negative) for investment strategy development, they have failed to  analyse changing market conditions. Investors are interested less in knowing the  statistical significance of their strategies, than in knowing whether their  strategy will work in the future. Whether it will work in the future is dependent  on the durability of market conditions which existed while developing it.</p> <p>Marcos Lopez de Prado, 2019.</p> <p>Phase identification enables investors to more accurately assess economic  regimes through time, beyond the ongoing switch between market risk-on and off.  It makes the point of new paradigm for both quant and fundamental PMs, in order  to identify a cause-effect mechanism to develop a thematic and capturing  asymmetrical distribution:</p> <ul> <li>Avoid all-regime strategies (Marcos Lopez de Prado, 2019)</li> <li>Allow regime-specific mean and standard deviation estimates</li> </ul> <p>Maximising returns means applying the below dynamic investment approach  associated with a cycle:</p> <ul> <li>Contrarian: When the rate of change is null (peak/trough)<ul> <li>Long risky assets as they fall</li> <li>Short risky assets as they rise</li> </ul> </li> <li>Trend-following otherwise (momentum - crowded investment styles)<ul> <li>Long risky assets as they rise</li> <li>Short risky assets as they fall</li> </ul> </li> </ul> <p>Understanding the balance between the size of the two groups is essential for  market behaviour:</p> <ul> <li>When contrarian strategies succeed for a while, they attract followers and  markets may become too stable (slow to adjust to economic developments)</li> <li>Conversely, when momentum strategies succeed for a while, they attract new  followers and markets may become too volatile (as such overreacting to news flows)</li> </ul> <p>Excess popularity of one approach eventually results in excess gains for the  opposite style, a process which over time should drive toward a balance. </p> <p>Long-Term Returns</p> <p>Therefore, long term returns should be positive (negative) only if the  overall average cycle trend is upward (downward) sloping. We call this  phenomenon Growth or wealth creation (destruction).</p>"},{"location":"model_glossary/phase_identification/factor_performance/","title":"\ud83d\udd12 Factor Performance","text":"<p>Used by practitioners</p> <p>Similar strategy presented by State Street SPDR Americas Research, Sector  Business Cycle Analysis and Orion Capital Partners1</p> <p>The scientific method is an empirical method of acquiring knowledge that has  characterized the development of science. It involves observation and skepticism,  given that cognitive assumptions can distort how one interprets the observation.  We first tend to identify market and economic regimes with both data  input and rational methods. We then analyse market performance, through the  lens of the below groupings:</p> <ul> <li>GICS GICS - Global Industry Classification Standard</li> <li>Risk factors Factor Performance in Bull and Bear Markets or Factor\u2019s Performance During Various Market Cycles, both from QuantPedia</li> <li>Network graph, based on correlation or factor similarity (e.g. factor contribution, dominant factor polymodels)</li> </ul> <ol> <li> <p>G. Monarcha, A systematic macro-based approach to sector rotation, Head  of Research, Orion Financial Partners, June 2022 update (First version: September 2021))\u00a0\u21a9</p> </li> </ol>"},{"location":"model_glossary/phase_identification/markov_models/","title":"\ud83d\udd12 Markov Models","text":""},{"location":"model_glossary/phase_identification/markov_models/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/phase_identification/signal_models/","title":"\ud83d\udd12 Signal Models","text":""},{"location":"model_glossary/phase_identification/signal_models/#introduction","title":"Introduction","text":"<p>In order to guide asset allocation decisions and allocate to industries at the optimal time, we believe the growth cycle plays an important role. We combine top-down insights and expert bottom-up fundamental analysis to understand the dynamics and drivers that determine industry performance within the cycle. In addition, the duration of a traditional growth cycle is considered in terms of years and is often referenced in relation to the progression of credit growth and capital expenditure in a particular economy.</p>"},{"location":"model_glossary/phase_identification/signal_models/#economic-cycles","title":"Economic cycles","text":""},{"location":"model_glossary/phase_identification/signal_models/#classical-business-cycle","title":"Classical business cycle","text":"<p>Business cycles are a type of fluctuation found in the aggregate economic activity of nations that organize their work mainly in business enterprises: a cycle consists of expansions occurring at about the same time in many economic activities, followed by similarly general recessions, contractions, and revivals which merge into the expansion phase of the next cycle.</p> <p>Burns and Mitchell, 1946</p> <p>The business cycle is meant to reproduce the cycle of the global level of activity of a country. The turning points of that cycle:</p> <ul> <li>Peak \u201cB\u201d</li> <li>Trough \u201cC\u201d</li> </ul> <p>are separate periods of recessions from periods of expansions.</p> <pre><code>flowchart LR\n  B --&gt; C;\n  C --&gt; B;</code></pre> <p>Burns and Mitchell (1946) point out two main stylised facts of the economic cycle:</p> <ol> <li>Correlation among individual economic variables: Most of macroeconomic time series evolve together along the cycle</li> <li>Non-linearity: The effect of a shock depends on the rest of the economic environment. In other words, economic dynamics during economically stressful times are potentially different from normal times. For instance, small shock, such as a decrease in housing prices, can sometimes have large effects, such as recessions</li> </ol>"},{"location":"model_glossary/phase_identification/signal_models/#the-growth-cycle","title":"The growth cycle","text":"<p>Definition introduced by Mintz (1974):</p> <ul> <li>Fluctuations of the GDP around its long-term trend</li> <li>Absolute prolonged declines in the level of economic activity tend to be rare events, so that in practice many economies do not very often exhibit recessions in classical terms</li> </ul> <p>Growth cycle turning points have a clear meaning: </p> <ul> <li>Peak \u201cA\u201d is reached when the growth rate decreases below the trend growth rate </li> <li>Trough \u201cD\u201d is reached when the growth rate overpasses it again</li> </ul> <pre><code>flowchart LR\n  A --&gt; D;\n  D --&gt; A;</code></pre> <p>Those downward and upward phases are respectively named slowdown and acceleration.</p> <p>Long-Term Trend</p> <p>If the long-term trend is considered as the estimated potential level (the potential output is the maximum amount of goods and services an economy can turn out at full capacity), then the growth cycle equals the output gap. </p> <p>A turning point of the output gap occurs when the current growth rate of the activity is above or below the potential growth rate, thereby signalling increasing or decreasing inflation pressures.</p>"},{"location":"model_glossary/phase_identification/signal_models/#the-abcd-approach","title":"The ABCD approach","text":"<p>Traditional growth cycle models tend to assume a linear progression through four discrete phases within the growth cycle: </p> <ul> <li>Recovery</li> <li>Expansion</li> <li>Slowdown</li> <li>Contraction</li> </ul> <p>The ABCD approach (Anas and Ferrara, 2004) refines the description of different economic phases by jointly considering the classical business cycle and the growth cycle:</p> <ul> <li>Let us suppose that the current growth rate of the activity is above the trend growth rate (acceleration phase)</li> <li>Point \u201cA\u201d: The downward movement will first materialize when the growth rate will decrease below the trend growth rate</li> <li>Point \u201cB\u201d: If the slowdown gains in intensity, the growth rate could become negative enough to provoke a recession</li> <li>Point \u201cC\u201d: Eventually, the economy should start to recover and exits from the recession</li> <li>Point \u201cD\u201d: As the recovery strengthens, the growth rate should overpass its trend. However, a slowdown will not automatically translate into a recession: if the slowdown is not severe enough to become a recession, then Point \u201cA\u201d will not be followed by Point \u201cB\u201d, but by Point \u201cD\u201d.</li> </ul> <pre><code>flowchart LR\n  A --- B &amp; D --- C;</code></pre> <p>Note on Cycles</p> <p>This framework improves thus the classical analysis of economic cycles by allowing sometimes two distinct phases, if the slowdown is not severe enough to become a recession, and sometimes four distinct phases, if the growth rate of the economy becomes negative enough to provoke a recession. In other words, all recessions involve slowdowns, but not all slowdowns involve recessions.</p>"},{"location":"model_glossary/phase_identification/signal_models/#the-non-linear-approach","title":"The non-linear approach","text":"<p>An alternative construct, where a growth cycle consists of six phases and progresses in a non-linear fashion, with each phase playing out over approximately four-to-six months. A six-phase model can, in our view, better explain the growth narrative as well as offer a consistent framework to understanding industry returns across emerging markets equities</p> <p>The six-phase growth model \u2014 constructed using a large set of high frequency macroeconomic indicators from different different economies \u2014 tracks the transition across the stages of the cycle in a more consistent manner when compared to traditional models.</p> <pre><code>flowchart LR\n  AD -.-&gt; A --- B &amp; D --- C;\n  C -.-&gt; BC;\n  BC -.-&gt; C;\n  A -.-&gt; AD;</code></pre> <p>For example, the growth model can depict the transition from the recovery phase to the expansion phase of the cycle, while also accounting for the alternative scenario that can occur when a recovery fails to take hold \u2014 as it repeatedly did, for example, in emerging markets between 2011 and 2015. Similarly, a slowdown phase does not always transition into a contraction phase per the traditional model. Our growth model accounts for periods when a slowdown is followed by a re-acceleration in growth before slowing again, as emerging markets experienced between 2004 and 2007.</p>"},{"location":"model_glossary/phase_identification/cluster_models/","title":"\ud83d\udd12 Cluster Models","text":""},{"location":"model_glossary/phase_identification/cluster_models/#time-series-classification","title":"Time-series classification","text":"<p>Time-series classification is a general task that can be useful to identify  regime change or predefined groups, using labeled training data.</p> <p>Multi-label classification is a process of categorizing a given set of time interval data into multiple classes. It requires the machine to learn how to  assign a class label to examples from the problem domain.</p> <p>Multi-label classification is a supervised machine learning module that is used  for classifying time interval data into groups. The goal is to predict the  categorical class labels. A vast body of research could be implemented, on top  of pre-processing features that prepare the data for modeling. In python,  Pycaret  has over 18 ready-to-use algorithms and several plots to analyze the  performance of trained models (e.g. ROC curve, confusion matrix).</p>"},{"location":"model_glossary/phase_identification/cluster_models/asset_allocation/","title":"\ud83d\udd12 Asset Allocation","text":""},{"location":"model_glossary/phase_identification/cluster_models/asset_allocation/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/phase_identification/cluster_models/gaussian_mixture/","title":"\ud83d\udd12 Gaussian Mixture","text":""},{"location":"model_glossary/phase_identification/cluster_models/gaussian_mixture/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/sentiment/hurst_exponent/","title":"\ud83d\udd12 Hurst Exponent","text":""},{"location":"model_glossary/sentiment/hurst_exponent/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/sentiment/range_strategy_models/","title":"\ud83d\udd12 Range Strategy","text":""},{"location":"model_glossary/sentiment/range_strategy_models/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/sentiment/reversion_models/","title":"\ud83d\udd12 Reversion Models","text":""},{"location":"model_glossary/sentiment/reversion_models/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/sentiment/short_interest_models/","title":"\ud83d\udd12 Short-Interest Models","text":""},{"location":"model_glossary/sentiment/short_interest_models/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/sentiment/trend_following_models/","title":"\ud83d\udd12 Trend Following Models","text":""},{"location":"model_glossary/sentiment/trend_following_models/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"model_glossary/valuation/zscore_models/","title":"\ud83d\udd12 Zscore Models","text":""},{"location":"model_glossary/valuation/zscore_models/#docs-in-progress","title":"DOCS IN PROGRESS","text":""},{"location":"terminal/","title":"Terminal","text":""},{"location":"terminal/#docs-in-progress","title":"DOCS IN PROGRESS","text":""}]}